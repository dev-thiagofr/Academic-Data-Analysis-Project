2024-06-06 09:55:48,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-06 09:55:48,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-06 09:55:48,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-06 09:55:48,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-06 10:34:56,467:INFO:PyCaret RegressionExperiment
2024-06-06 10:34:56,470:INFO:Logging name: reg-default-name
2024-06-06 10:34:56,477:INFO:ML Usecase: MLUsecase.REGRESSION
2024-06-06 10:34:56,477:INFO:version 3.3.2
2024-06-06 10:34:56,477:INFO:Initializing setup()
2024-06-06 10:34:56,478:INFO:self.USI: 7226
2024-06-06 10:34:56,478:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'transform_target_param', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'X_test'}
2024-06-06 10:34:56,478:INFO:Checking environment
2024-06-06 10:34:56,479:INFO:python_version: 3.11.5
2024-06-06 10:34:56,479:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 10:34:56,479:INFO:machine: AMD64
2024-06-06 10:34:56,479:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 10:34:56,480:INFO:Memory: svmem(total=21420621824, available=6319476736, percent=70.5, used=15101145088, free=6319476736)
2024-06-06 10:34:56,480:INFO:Physical Core: 4
2024-06-06 10:34:56,480:INFO:Logical Core: 4
2024-06-06 10:34:56,480:INFO:Checking libraries
2024-06-06 10:34:56,481:INFO:System:
2024-06-06 10:34:56,481:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 10:34:56,481:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 10:34:56,481:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 10:34:56,482:INFO:PyCaret required dependencies:
2024-06-06 10:34:58,662:INFO:                 pip: 23.2.1
2024-06-06 10:34:58,663:INFO:          setuptools: 68.0.0
2024-06-06 10:34:58,663:INFO:             pycaret: 3.3.2
2024-06-06 10:34:58,663:INFO:             IPython: 8.20.0
2024-06-06 10:34:58,663:INFO:          ipywidgets: 8.1.2
2024-06-06 10:34:58,663:INFO:                tqdm: 4.65.0
2024-06-06 10:34:58,663:INFO:               numpy: 1.26.4
2024-06-06 10:34:58,664:INFO:              pandas: 1.5.3
2024-06-06 10:34:58,664:INFO:              jinja2: 3.1.3
2024-06-06 10:34:58,664:INFO:               scipy: 1.11.4
2024-06-06 10:34:58,664:INFO:              joblib: 1.2.0
2024-06-06 10:34:58,664:INFO:             sklearn: 1.4.2
2024-06-06 10:34:58,664:INFO:                pyod: 2.0.0
2024-06-06 10:34:58,664:INFO:            imblearn: 0.12.3
2024-06-06 10:34:58,665:INFO:   category_encoders: 2.6.3
2024-06-06 10:34:58,665:INFO:            lightgbm: 4.3.0
2024-06-06 10:34:58,665:INFO:               numba: 0.59.1
2024-06-06 10:34:58,666:INFO:            requests: 2.31.0
2024-06-06 10:34:58,666:INFO:          matplotlib: 3.7.5
2024-06-06 10:34:58,666:INFO:          scikitplot: 0.3.7
2024-06-06 10:34:58,666:INFO:         yellowbrick: 1.5
2024-06-06 10:34:58,666:INFO:              plotly: 5.19.0
2024-06-06 10:34:58,666:INFO:    plotly-resampler: Not installed
2024-06-06 10:34:58,667:INFO:             kaleido: 0.2.1
2024-06-06 10:34:58,667:INFO:           schemdraw: 0.15
2024-06-06 10:34:58,667:INFO:         statsmodels: 0.14.0
2024-06-06 10:34:58,667:INFO:              sktime: 0.26.0
2024-06-06 10:34:58,667:INFO:               tbats: 1.1.3
2024-06-06 10:34:58,667:INFO:            pmdarima: 2.0.4
2024-06-06 10:34:58,668:INFO:              psutil: 5.9.0
2024-06-06 10:34:58,668:INFO:          markupsafe: 2.1.3
2024-06-06 10:34:58,668:INFO:             pickle5: Not installed
2024-06-06 10:34:58,668:INFO:         cloudpickle: 2.2.1
2024-06-06 10:34:58,668:INFO:         deprecation: 2.1.0
2024-06-06 10:34:58,668:INFO:              xxhash: 2.0.2
2024-06-06 10:34:58,668:INFO:           wurlitzer: Not installed
2024-06-06 10:34:58,669:INFO:PyCaret optional dependencies:
2024-06-06 10:34:58,812:INFO:                shap: Not installed
2024-06-06 10:34:58,813:INFO:           interpret: Not installed
2024-06-06 10:34:58,813:INFO:                umap: Not installed
2024-06-06 10:34:58,814:INFO:     ydata_profiling: Not installed
2024-06-06 10:34:58,814:INFO:  explainerdashboard: Not installed
2024-06-06 10:34:58,815:INFO:             autoviz: Not installed
2024-06-06 10:34:58,816:INFO:           fairlearn: Not installed
2024-06-06 10:34:58,816:INFO:          deepchecks: Not installed
2024-06-06 10:34:58,817:INFO:             xgboost: 2.0.3
2024-06-06 10:34:58,817:INFO:            catboost: Not installed
2024-06-06 10:34:58,817:INFO:              kmodes: Not installed
2024-06-06 10:34:58,817:INFO:             mlxtend: Not installed
2024-06-06 10:34:58,817:INFO:       statsforecast: Not installed
2024-06-06 10:34:58,818:INFO:        tune_sklearn: Not installed
2024-06-06 10:34:58,818:INFO:                 ray: Not installed
2024-06-06 10:34:58,818:INFO:            hyperopt: Not installed
2024-06-06 10:34:58,818:INFO:              optuna: Not installed
2024-06-06 10:34:58,818:INFO:               skopt: Not installed
2024-06-06 10:34:58,818:INFO:              mlflow: Not installed
2024-06-06 10:34:58,819:INFO:              gradio: Not installed
2024-06-06 10:34:58,819:INFO:             fastapi: Not installed
2024-06-06 10:34:58,819:INFO:             uvicorn: Not installed
2024-06-06 10:34:58,819:INFO:              m2cgen: Not installed
2024-06-06 10:34:58,819:INFO:           evidently: Not installed
2024-06-06 10:34:58,819:INFO:               fugue: Not installed
2024-06-06 10:34:58,820:INFO:           streamlit: Not installed
2024-06-06 10:34:58,820:INFO:             prophet: Not installed
2024-06-06 10:34:58,820:INFO:None
2024-06-06 10:34:58,820:INFO:Set up data.
2024-06-06 10:34:58,855:INFO:Set up folding strategy.
2024-06-06 10:34:58,856:INFO:Set up train/test split.
2024-06-06 10:34:58,874:INFO:Set up index.
2024-06-06 10:34:58,876:INFO:Assigning column types.
2024-06-06 10:34:58,892:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 10:34:58,892:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 10:34:58,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:34:58,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,101:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:34:59,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:34:59,106:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,114:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,122:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,308:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:34:59,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:34:59,314:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-06-06 10:34:59,323:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,522:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:34:59,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:34:59,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,734:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:34:59,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:34:59,740:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-06-06 10:34:59,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:34:59,946:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:34:59,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:34:59,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,156:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:00,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:00,161:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-06-06 10:35:00,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,369:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:00,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:00,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,579:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:00,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:00,584:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 10:35:00,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:35:00,790:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:00,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:00,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:35:01,007:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:01,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:01,013:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-06-06 10:35:01,223:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:01,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:01,446:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:01,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:01,457:INFO:Preparing preprocessing pipeline...
2024-06-06 10:35:01,457:INFO:Set up simple imputation.
2024-06-06 10:35:01,460:INFO:Set up column name cleaning.
2024-06-06 10:35:01,545:INFO:Finished creating preprocessing pipeline.
2024-06-06 10:35:01,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['ID', 'FLAG_CARRO', 'FLAG_IMOVEL',
                                             'QTD_FILHOS', 'GANHO_ANUAL',
                                             'IDADE', 'DIAS_TRABALHADOS',
                                             'FLAG_CELULAR', 'FLAG_CELULAR_EMP',
                                             'FLAG_EMAIL', 'QTD_FAMILIARES',
                                             'F', 'M', 'Civil marriage',
                                             'Married', 'Separated',
                                             'Single / not married', '...
                                             'Student', 'Working',
                                             'Co-op apartment',
                                             'House / apartment',
                                             'Municipal apartment',
                                             'Office apartment',
                                             'Rented apartment', 'With parents',
                                             'Academic degree', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-06-06 10:35:01,556:INFO:Creating final display dataframe.
2024-06-06 10:35:01,814:INFO:Setup _display_container:                     Description             Value
0                    Session id              6691
1                        Target            STATUS
2                   Target type        Regression
3           Original data shape       (36451, 36)
4        Transformed data shape       (36451, 36)
5   Transformed train set shape       (25515, 36)
6    Transformed test set shape       (10936, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7226
2024-06-06 10:35:02,126:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:02,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:02,355:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:35:02,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:35:02,363:INFO:setup() successfully completed in 6.24s...............
2024-06-06 10:35:41,792:INFO:Initializing create_model()
2024-06-06 10:35:41,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:35:41,804:INFO:Checking exceptions
2024-06-06 10:35:41,883:INFO:Importing libraries
2024-06-06 10:35:41,907:INFO:Copying training dataset
2024-06-06 10:35:41,953:INFO:Defining folds
2024-06-06 10:35:41,953:INFO:Declaring metric variables
2024-06-06 10:35:41,982:INFO:Importing untrained model
2024-06-06 10:35:42,147:INFO:Linear Regression Imported successfully
2024-06-06 10:35:42,199:INFO:Starting cross validation
2024-06-06 10:35:42,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:35:52,554:INFO:Calculating mean and std
2024-06-06 10:35:52,555:INFO:Creating metrics dataframe
2024-06-06 10:35:52,572:INFO:Finalizing model
2024-06-06 10:35:52,696:INFO:Uploading results into container
2024-06-06 10:35:52,702:INFO:Uploading model into container now
2024-06-06 10:35:52,717:INFO:_master_model_container: 1
2024-06-06 10:35:52,719:INFO:_display_container: 2
2024-06-06 10:35:52,720:INFO:LinearRegression(n_jobs=-1)
2024-06-06 10:35:52,720:INFO:create_model() successfully completed......................................
2024-06-06 10:36:17,757:INFO:Initializing compare_models()
2024-06-06 10:36:17,764:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-06-06 10:36:17,768:INFO:Checking exceptions
2024-06-06 10:36:17,782:INFO:Preparing display monitor
2024-06-06 10:36:17,830:INFO:Initializing Linear Regression
2024-06-06 10:36:17,864:INFO:Total runtime is 0.0005666772524515788 minutes
2024-06-06 10:36:17,876:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:17,886:INFO:Initializing create_model()
2024-06-06 10:36:17,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:17,900:INFO:Checking exceptions
2024-06-06 10:36:17,902:INFO:Importing libraries
2024-06-06 10:36:17,902:INFO:Copying training dataset
2024-06-06 10:36:17,964:INFO:Defining folds
2024-06-06 10:36:17,970:INFO:Declaring metric variables
2024-06-06 10:36:17,981:INFO:Importing untrained model
2024-06-06 10:36:17,996:INFO:Linear Regression Imported successfully
2024-06-06 10:36:18,014:INFO:Starting cross validation
2024-06-06 10:36:18,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:18,778:INFO:Calculating mean and std
2024-06-06 10:36:18,779:INFO:Creating metrics dataframe
2024-06-06 10:36:18,782:INFO:Uploading results into container
2024-06-06 10:36:18,784:INFO:Uploading model into container now
2024-06-06 10:36:18,785:INFO:_master_model_container: 2
2024-06-06 10:36:18,785:INFO:_display_container: 3
2024-06-06 10:36:18,786:INFO:LinearRegression(n_jobs=-1)
2024-06-06 10:36:18,786:INFO:create_model() successfully completed......................................
2024-06-06 10:36:18,911:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:18,911:INFO:Creating metrics dataframe
2024-06-06 10:36:18,927:INFO:Initializing Lasso Regression
2024-06-06 10:36:18,928:INFO:Total runtime is 0.01831802527109782 minutes
2024-06-06 10:36:18,933:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:18,934:INFO:Initializing create_model()
2024-06-06 10:36:18,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:18,936:INFO:Checking exceptions
2024-06-06 10:36:18,936:INFO:Importing libraries
2024-06-06 10:36:18,936:INFO:Copying training dataset
2024-06-06 10:36:18,957:INFO:Defining folds
2024-06-06 10:36:18,961:INFO:Declaring metric variables
2024-06-06 10:36:18,968:INFO:Importing untrained model
2024-06-06 10:36:18,977:INFO:Lasso Regression Imported successfully
2024-06-06 10:36:18,989:INFO:Starting cross validation
2024-06-06 10:36:18,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:19,616:INFO:Calculating mean and std
2024-06-06 10:36:19,618:INFO:Creating metrics dataframe
2024-06-06 10:36:19,622:INFO:Uploading results into container
2024-06-06 10:36:19,624:INFO:Uploading model into container now
2024-06-06 10:36:19,631:INFO:_master_model_container: 3
2024-06-06 10:36:19,632:INFO:_display_container: 3
2024-06-06 10:36:19,633:INFO:Lasso(random_state=6691)
2024-06-06 10:36:19,633:INFO:create_model() successfully completed......................................
2024-06-06 10:36:19,759:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:19,759:INFO:Creating metrics dataframe
2024-06-06 10:36:19,775:INFO:Initializing Ridge Regression
2024-06-06 10:36:19,776:INFO:Total runtime is 0.03243571122487386 minutes
2024-06-06 10:36:19,782:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:19,783:INFO:Initializing create_model()
2024-06-06 10:36:19,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:19,784:INFO:Checking exceptions
2024-06-06 10:36:19,785:INFO:Importing libraries
2024-06-06 10:36:19,785:INFO:Copying training dataset
2024-06-06 10:36:19,806:INFO:Defining folds
2024-06-06 10:36:19,807:INFO:Declaring metric variables
2024-06-06 10:36:19,815:INFO:Importing untrained model
2024-06-06 10:36:19,822:INFO:Ridge Regression Imported successfully
2024-06-06 10:36:19,835:INFO:Starting cross validation
2024-06-06 10:36:19,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:20,506:INFO:Calculating mean and std
2024-06-06 10:36:20,508:INFO:Creating metrics dataframe
2024-06-06 10:36:20,519:INFO:Uploading results into container
2024-06-06 10:36:20,520:INFO:Uploading model into container now
2024-06-06 10:36:20,520:INFO:_master_model_container: 4
2024-06-06 10:36:20,521:INFO:_display_container: 3
2024-06-06 10:36:20,521:INFO:Ridge(random_state=6691)
2024-06-06 10:36:20,521:INFO:create_model() successfully completed......................................
2024-06-06 10:36:20,717:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:20,717:INFO:Creating metrics dataframe
2024-06-06 10:36:20,734:INFO:Initializing Elastic Net
2024-06-06 10:36:20,736:INFO:Total runtime is 0.048453605175018316 minutes
2024-06-06 10:36:20,740:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:20,741:INFO:Initializing create_model()
2024-06-06 10:36:20,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:20,742:INFO:Checking exceptions
2024-06-06 10:36:20,742:INFO:Importing libraries
2024-06-06 10:36:20,743:INFO:Copying training dataset
2024-06-06 10:36:20,770:INFO:Defining folds
2024-06-06 10:36:20,771:INFO:Declaring metric variables
2024-06-06 10:36:20,819:INFO:Importing untrained model
2024-06-06 10:36:20,843:INFO:Elastic Net Imported successfully
2024-06-06 10:36:20,870:INFO:Starting cross validation
2024-06-06 10:36:20,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:21,503:INFO:Calculating mean and std
2024-06-06 10:36:21,506:INFO:Creating metrics dataframe
2024-06-06 10:36:21,511:INFO:Uploading results into container
2024-06-06 10:36:21,513:INFO:Uploading model into container now
2024-06-06 10:36:21,514:INFO:_master_model_container: 5
2024-06-06 10:36:21,515:INFO:_display_container: 3
2024-06-06 10:36:21,515:INFO:ElasticNet(random_state=6691)
2024-06-06 10:36:21,516:INFO:create_model() successfully completed......................................
2024-06-06 10:36:21,645:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:21,646:INFO:Creating metrics dataframe
2024-06-06 10:36:21,662:INFO:Initializing Least Angle Regression
2024-06-06 10:36:21,662:INFO:Total runtime is 0.06388805309931438 minutes
2024-06-06 10:36:21,670:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:21,670:INFO:Initializing create_model()
2024-06-06 10:36:21,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:21,672:INFO:Checking exceptions
2024-06-06 10:36:21,673:INFO:Importing libraries
2024-06-06 10:36:21,673:INFO:Copying training dataset
2024-06-06 10:36:21,697:INFO:Defining folds
2024-06-06 10:36:21,697:INFO:Declaring metric variables
2024-06-06 10:36:21,705:INFO:Importing untrained model
2024-06-06 10:36:21,710:INFO:Least Angle Regression Imported successfully
2024-06-06 10:36:21,724:INFO:Starting cross validation
2024-06-06 10:36:21,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:21,923:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.530e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:21,928:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.218e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:21,933:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.002e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:21,946:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.850e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:21,947:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.291e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,163:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.572e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,176:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.942e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,199:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.152e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,210:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=9.834e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,264:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=5.352e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,266:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.335e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,268:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.627e-03, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-06-06 10:36:22,321:INFO:Calculating mean and std
2024-06-06 10:36:22,323:INFO:Creating metrics dataframe
2024-06-06 10:36:22,331:INFO:Uploading results into container
2024-06-06 10:36:22,332:INFO:Uploading model into container now
2024-06-06 10:36:22,333:INFO:_master_model_container: 6
2024-06-06 10:36:22,333:INFO:_display_container: 3
2024-06-06 10:36:22,333:INFO:Lars(random_state=6691)
2024-06-06 10:36:22,334:INFO:create_model() successfully completed......................................
2024-06-06 10:36:22,466:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:22,466:INFO:Creating metrics dataframe
2024-06-06 10:36:22,485:INFO:Initializing Lasso Least Angle Regression
2024-06-06 10:36:22,485:INFO:Total runtime is 0.07760573228200277 minutes
2024-06-06 10:36:22,493:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:22,493:INFO:Initializing create_model()
2024-06-06 10:36:22,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:22,494:INFO:Checking exceptions
2024-06-06 10:36:22,494:INFO:Importing libraries
2024-06-06 10:36:22,494:INFO:Copying training dataset
2024-06-06 10:36:22,516:INFO:Defining folds
2024-06-06 10:36:22,517:INFO:Declaring metric variables
2024-06-06 10:36:22,529:INFO:Importing untrained model
2024-06-06 10:36:22,539:INFO:Lasso Least Angle Regression Imported successfully
2024-06-06 10:36:22,553:INFO:Starting cross validation
2024-06-06 10:36:22,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:23,118:INFO:Calculating mean and std
2024-06-06 10:36:23,120:INFO:Creating metrics dataframe
2024-06-06 10:36:23,128:INFO:Uploading results into container
2024-06-06 10:36:23,130:INFO:Uploading model into container now
2024-06-06 10:36:23,131:INFO:_master_model_container: 7
2024-06-06 10:36:23,132:INFO:_display_container: 3
2024-06-06 10:36:23,132:INFO:LassoLars(random_state=6691)
2024-06-06 10:36:23,133:INFO:create_model() successfully completed......................................
2024-06-06 10:36:23,255:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:23,255:INFO:Creating metrics dataframe
2024-06-06 10:36:23,272:INFO:Initializing Orthogonal Matching Pursuit
2024-06-06 10:36:23,275:INFO:Total runtime is 0.0907734473546346 minutes
2024-06-06 10:36:23,281:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:23,281:INFO:Initializing create_model()
2024-06-06 10:36:23,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:23,282:INFO:Checking exceptions
2024-06-06 10:36:23,283:INFO:Importing libraries
2024-06-06 10:36:23,283:INFO:Copying training dataset
2024-06-06 10:36:23,304:INFO:Defining folds
2024-06-06 10:36:23,319:INFO:Declaring metric variables
2024-06-06 10:36:23,327:INFO:Importing untrained model
2024-06-06 10:36:23,334:INFO:Orthogonal Matching Pursuit Imported successfully
2024-06-06 10:36:23,347:INFO:Starting cross validation
2024-06-06 10:36:23,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:23,931:INFO:Calculating mean and std
2024-06-06 10:36:23,933:INFO:Creating metrics dataframe
2024-06-06 10:36:23,938:INFO:Uploading results into container
2024-06-06 10:36:23,940:INFO:Uploading model into container now
2024-06-06 10:36:23,943:INFO:_master_model_container: 8
2024-06-06 10:36:23,946:INFO:_display_container: 3
2024-06-06 10:36:23,947:INFO:OrthogonalMatchingPursuit()
2024-06-06 10:36:23,947:INFO:create_model() successfully completed......................................
2024-06-06 10:36:24,073:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:24,074:INFO:Creating metrics dataframe
2024-06-06 10:36:24,094:INFO:Initializing Bayesian Ridge
2024-06-06 10:36:24,095:INFO:Total runtime is 0.10444111029307047 minutes
2024-06-06 10:36:24,100:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:24,100:INFO:Initializing create_model()
2024-06-06 10:36:24,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:24,101:INFO:Checking exceptions
2024-06-06 10:36:24,102:INFO:Importing libraries
2024-06-06 10:36:24,102:INFO:Copying training dataset
2024-06-06 10:36:24,123:INFO:Defining folds
2024-06-06 10:36:24,123:INFO:Declaring metric variables
2024-06-06 10:36:24,135:INFO:Importing untrained model
2024-06-06 10:36:24,141:INFO:Bayesian Ridge Imported successfully
2024-06-06 10:36:24,155:INFO:Starting cross validation
2024-06-06 10:36:24,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:25,478:INFO:Calculating mean and std
2024-06-06 10:36:25,482:INFO:Creating metrics dataframe
2024-06-06 10:36:25,491:INFO:Uploading results into container
2024-06-06 10:36:25,492:INFO:Uploading model into container now
2024-06-06 10:36:25,493:INFO:_master_model_container: 9
2024-06-06 10:36:25,494:INFO:_display_container: 3
2024-06-06 10:36:25,494:INFO:BayesianRidge()
2024-06-06 10:36:25,495:INFO:create_model() successfully completed......................................
2024-06-06 10:36:25,720:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:25,721:INFO:Creating metrics dataframe
2024-06-06 10:36:25,740:INFO:Initializing Passive Aggressive Regressor
2024-06-06 10:36:25,740:INFO:Total runtime is 0.1318597992261251 minutes
2024-06-06 10:36:25,746:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:25,746:INFO:Initializing create_model()
2024-06-06 10:36:25,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:25,747:INFO:Checking exceptions
2024-06-06 10:36:25,749:INFO:Importing libraries
2024-06-06 10:36:25,750:INFO:Copying training dataset
2024-06-06 10:36:25,772:INFO:Defining folds
2024-06-06 10:36:25,773:INFO:Declaring metric variables
2024-06-06 10:36:25,780:INFO:Importing untrained model
2024-06-06 10:36:25,794:INFO:Passive Aggressive Regressor Imported successfully
2024-06-06 10:36:25,809:INFO:Starting cross validation
2024-06-06 10:36:25,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:26,545:INFO:Calculating mean and std
2024-06-06 10:36:26,546:INFO:Creating metrics dataframe
2024-06-06 10:36:26,555:INFO:Uploading results into container
2024-06-06 10:36:26,559:INFO:Uploading model into container now
2024-06-06 10:36:26,560:INFO:_master_model_container: 10
2024-06-06 10:36:26,560:INFO:_display_container: 3
2024-06-06 10:36:26,561:INFO:PassiveAggressiveRegressor(random_state=6691)
2024-06-06 10:36:26,561:INFO:create_model() successfully completed......................................
2024-06-06 10:36:26,697:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:26,698:INFO:Creating metrics dataframe
2024-06-06 10:36:26,721:INFO:Initializing Huber Regressor
2024-06-06 10:36:26,723:INFO:Total runtime is 0.14824437697728476 minutes
2024-06-06 10:36:26,729:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:26,731:INFO:Initializing create_model()
2024-06-06 10:36:26,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:26,732:INFO:Checking exceptions
2024-06-06 10:36:26,732:INFO:Importing libraries
2024-06-06 10:36:26,733:INFO:Copying training dataset
2024-06-06 10:36:26,767:INFO:Defining folds
2024-06-06 10:36:26,767:INFO:Declaring metric variables
2024-06-06 10:36:26,779:INFO:Importing untrained model
2024-06-06 10:36:26,790:INFO:Huber Regressor Imported successfully
2024-06-06 10:36:26,817:INFO:Starting cross validation
2024-06-06 10:36:26,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:28,848:INFO:Calculating mean and std
2024-06-06 10:36:28,850:INFO:Creating metrics dataframe
2024-06-06 10:36:28,854:INFO:Uploading results into container
2024-06-06 10:36:28,855:INFO:Uploading model into container now
2024-06-06 10:36:28,858:INFO:_master_model_container: 11
2024-06-06 10:36:28,863:INFO:_display_container: 3
2024-06-06 10:36:28,863:INFO:HuberRegressor()
2024-06-06 10:36:28,864:INFO:create_model() successfully completed......................................
2024-06-06 10:36:28,985:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:28,985:INFO:Creating metrics dataframe
2024-06-06 10:36:29,002:INFO:Initializing K Neighbors Regressor
2024-06-06 10:36:29,002:INFO:Total runtime is 0.18623051246007286 minutes
2024-06-06 10:36:29,007:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:29,008:INFO:Initializing create_model()
2024-06-06 10:36:29,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:29,012:INFO:Checking exceptions
2024-06-06 10:36:29,012:INFO:Importing libraries
2024-06-06 10:36:29,012:INFO:Copying training dataset
2024-06-06 10:36:29,032:INFO:Defining folds
2024-06-06 10:36:29,032:INFO:Declaring metric variables
2024-06-06 10:36:29,037:INFO:Importing untrained model
2024-06-06 10:36:29,048:INFO:K Neighbors Regressor Imported successfully
2024-06-06 10:36:29,068:INFO:Starting cross validation
2024-06-06 10:36:29,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:31,567:INFO:Calculating mean and std
2024-06-06 10:36:31,571:INFO:Creating metrics dataframe
2024-06-06 10:36:31,580:INFO:Uploading results into container
2024-06-06 10:36:31,581:INFO:Uploading model into container now
2024-06-06 10:36:31,581:INFO:_master_model_container: 12
2024-06-06 10:36:31,582:INFO:_display_container: 3
2024-06-06 10:36:31,582:INFO:KNeighborsRegressor(n_jobs=-1)
2024-06-06 10:36:31,582:INFO:create_model() successfully completed......................................
2024-06-06 10:36:31,722:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:31,722:INFO:Creating metrics dataframe
2024-06-06 10:36:31,741:INFO:Initializing Decision Tree Regressor
2024-06-06 10:36:31,741:INFO:Total runtime is 0.23186726570129396 minutes
2024-06-06 10:36:31,746:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:31,747:INFO:Initializing create_model()
2024-06-06 10:36:31,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:31,749:INFO:Checking exceptions
2024-06-06 10:36:31,749:INFO:Importing libraries
2024-06-06 10:36:31,749:INFO:Copying training dataset
2024-06-06 10:36:31,791:INFO:Defining folds
2024-06-06 10:36:31,797:INFO:Declaring metric variables
2024-06-06 10:36:31,801:INFO:Importing untrained model
2024-06-06 10:36:31,811:INFO:Decision Tree Regressor Imported successfully
2024-06-06 10:36:31,824:INFO:Starting cross validation
2024-06-06 10:36:31,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:36:33,794:INFO:Calculating mean and std
2024-06-06 10:36:33,797:INFO:Creating metrics dataframe
2024-06-06 10:36:33,804:INFO:Uploading results into container
2024-06-06 10:36:33,805:INFO:Uploading model into container now
2024-06-06 10:36:33,806:INFO:_master_model_container: 13
2024-06-06 10:36:33,806:INFO:_display_container: 3
2024-06-06 10:36:33,807:INFO:DecisionTreeRegressor(random_state=6691)
2024-06-06 10:36:33,807:INFO:create_model() successfully completed......................................
2024-06-06 10:36:33,940:INFO:SubProcess create_model() end ==================================
2024-06-06 10:36:33,940:INFO:Creating metrics dataframe
2024-06-06 10:36:33,958:INFO:Initializing Random Forest Regressor
2024-06-06 10:36:33,959:INFO:Total runtime is 0.2688367009162903 minutes
2024-06-06 10:36:33,966:INFO:SubProcess create_model() called ==================================
2024-06-06 10:36:33,967:INFO:Initializing create_model()
2024-06-06 10:36:33,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:36:33,969:INFO:Checking exceptions
2024-06-06 10:36:33,969:INFO:Importing libraries
2024-06-06 10:36:33,969:INFO:Copying training dataset
2024-06-06 10:36:33,990:INFO:Defining folds
2024-06-06 10:36:33,992:INFO:Declaring metric variables
2024-06-06 10:36:34,002:INFO:Importing untrained model
2024-06-06 10:36:34,043:INFO:Random Forest Regressor Imported successfully
2024-06-06 10:36:34,059:INFO:Starting cross validation
2024-06-06 10:36:34,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:37:33,592:INFO:Calculating mean and std
2024-06-06 10:37:33,594:INFO:Creating metrics dataframe
2024-06-06 10:37:33,603:INFO:Uploading results into container
2024-06-06 10:37:33,604:INFO:Uploading model into container now
2024-06-06 10:37:33,605:INFO:_master_model_container: 14
2024-06-06 10:37:33,605:INFO:_display_container: 3
2024-06-06 10:37:33,607:INFO:RandomForestRegressor(n_jobs=-1, random_state=6691)
2024-06-06 10:37:33,607:INFO:create_model() successfully completed......................................
2024-06-06 10:37:33,739:INFO:SubProcess create_model() end ==================================
2024-06-06 10:37:33,739:INFO:Creating metrics dataframe
2024-06-06 10:37:33,759:INFO:Initializing Extra Trees Regressor
2024-06-06 10:37:33,760:INFO:Total runtime is 1.2655287226041159 minutes
2024-06-06 10:37:33,765:INFO:SubProcess create_model() called ==================================
2024-06-06 10:37:33,766:INFO:Initializing create_model()
2024-06-06 10:37:33,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:37:33,766:INFO:Checking exceptions
2024-06-06 10:37:33,767:INFO:Importing libraries
2024-06-06 10:37:33,767:INFO:Copying training dataset
2024-06-06 10:37:33,790:INFO:Defining folds
2024-06-06 10:37:33,790:INFO:Declaring metric variables
2024-06-06 10:37:33,796:INFO:Importing untrained model
2024-06-06 10:37:33,802:INFO:Extra Trees Regressor Imported successfully
2024-06-06 10:37:33,821:INFO:Starting cross validation
2024-06-06 10:37:33,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:08,054:INFO:Calculating mean and std
2024-06-06 10:38:08,062:INFO:Creating metrics dataframe
2024-06-06 10:38:08,071:INFO:Uploading results into container
2024-06-06 10:38:08,073:INFO:Uploading model into container now
2024-06-06 10:38:08,075:INFO:_master_model_container: 15
2024-06-06 10:38:08,075:INFO:_display_container: 3
2024-06-06 10:38:08,076:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6691)
2024-06-06 10:38:08,077:INFO:create_model() successfully completed......................................
2024-06-06 10:38:08,212:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:08,212:INFO:Creating metrics dataframe
2024-06-06 10:38:08,233:INFO:Initializing AdaBoost Regressor
2024-06-06 10:38:08,233:INFO:Total runtime is 1.840070430437724 minutes
2024-06-06 10:38:08,239:INFO:SubProcess create_model() called ==================================
2024-06-06 10:38:08,241:INFO:Initializing create_model()
2024-06-06 10:38:08,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:08,242:INFO:Checking exceptions
2024-06-06 10:38:08,242:INFO:Importing libraries
2024-06-06 10:38:08,242:INFO:Copying training dataset
2024-06-06 10:38:08,262:INFO:Defining folds
2024-06-06 10:38:08,263:INFO:Declaring metric variables
2024-06-06 10:38:08,268:INFO:Importing untrained model
2024-06-06 10:38:08,279:INFO:AdaBoost Regressor Imported successfully
2024-06-06 10:38:08,295:INFO:Starting cross validation
2024-06-06 10:38:08,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:10,194:INFO:Calculating mean and std
2024-06-06 10:38:10,196:INFO:Creating metrics dataframe
2024-06-06 10:38:10,203:INFO:Uploading results into container
2024-06-06 10:38:10,204:INFO:Uploading model into container now
2024-06-06 10:38:10,205:INFO:_master_model_container: 16
2024-06-06 10:38:10,206:INFO:_display_container: 3
2024-06-06 10:38:10,206:INFO:AdaBoostRegressor(random_state=6691)
2024-06-06 10:38:10,206:INFO:create_model() successfully completed......................................
2024-06-06 10:38:10,324:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:10,324:INFO:Creating metrics dataframe
2024-06-06 10:38:10,345:INFO:Initializing Gradient Boosting Regressor
2024-06-06 10:38:10,345:INFO:Total runtime is 1.8752730528513593 minutes
2024-06-06 10:38:10,352:INFO:SubProcess create_model() called ==================================
2024-06-06 10:38:10,353:INFO:Initializing create_model()
2024-06-06 10:38:10,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:10,354:INFO:Checking exceptions
2024-06-06 10:38:10,354:INFO:Importing libraries
2024-06-06 10:38:10,355:INFO:Copying training dataset
2024-06-06 10:38:10,376:INFO:Defining folds
2024-06-06 10:38:10,376:INFO:Declaring metric variables
2024-06-06 10:38:10,386:INFO:Importing untrained model
2024-06-06 10:38:10,393:INFO:Gradient Boosting Regressor Imported successfully
2024-06-06 10:38:10,406:INFO:Starting cross validation
2024-06-06 10:38:10,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:25,110:INFO:Calculating mean and std
2024-06-06 10:38:25,112:INFO:Creating metrics dataframe
2024-06-06 10:38:25,116:INFO:Uploading results into container
2024-06-06 10:38:25,118:INFO:Uploading model into container now
2024-06-06 10:38:25,121:INFO:_master_model_container: 17
2024-06-06 10:38:25,121:INFO:_display_container: 3
2024-06-06 10:38:25,124:INFO:GradientBoostingRegressor(random_state=6691)
2024-06-06 10:38:25,124:INFO:create_model() successfully completed......................................
2024-06-06 10:38:25,240:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:25,241:INFO:Creating metrics dataframe
2024-06-06 10:38:25,259:INFO:Initializing Extreme Gradient Boosting
2024-06-06 10:38:25,259:INFO:Total runtime is 2.1238416075706485 minutes
2024-06-06 10:38:25,265:INFO:SubProcess create_model() called ==================================
2024-06-06 10:38:25,267:INFO:Initializing create_model()
2024-06-06 10:38:25,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:25,268:INFO:Checking exceptions
2024-06-06 10:38:25,268:INFO:Importing libraries
2024-06-06 10:38:25,268:INFO:Copying training dataset
2024-06-06 10:38:25,286:INFO:Defining folds
2024-06-06 10:38:25,288:INFO:Declaring metric variables
2024-06-06 10:38:25,293:INFO:Importing untrained model
2024-06-06 10:38:25,303:INFO:Extreme Gradient Boosting Imported successfully
2024-06-06 10:38:25,322:INFO:Starting cross validation
2024-06-06 10:38:25,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:27,619:INFO:Calculating mean and std
2024-06-06 10:38:27,620:INFO:Creating metrics dataframe
2024-06-06 10:38:27,629:INFO:Uploading results into container
2024-06-06 10:38:27,630:INFO:Uploading model into container now
2024-06-06 10:38:27,631:INFO:_master_model_container: 18
2024-06-06 10:38:27,631:INFO:_display_container: 3
2024-06-06 10:38:27,632:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=6691, ...)
2024-06-06 10:38:27,632:INFO:create_model() successfully completed......................................
2024-06-06 10:38:27,742:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:27,742:INFO:Creating metrics dataframe
2024-06-06 10:38:27,759:INFO:Initializing Light Gradient Boosting Machine
2024-06-06 10:38:27,760:INFO:Total runtime is 2.1655114054679876 minutes
2024-06-06 10:38:27,766:INFO:SubProcess create_model() called ==================================
2024-06-06 10:38:27,767:INFO:Initializing create_model()
2024-06-06 10:38:27,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:27,768:INFO:Checking exceptions
2024-06-06 10:38:27,769:INFO:Importing libraries
2024-06-06 10:38:27,769:INFO:Copying training dataset
2024-06-06 10:38:27,787:INFO:Defining folds
2024-06-06 10:38:27,788:INFO:Declaring metric variables
2024-06-06 10:38:27,796:INFO:Importing untrained model
2024-06-06 10:38:27,803:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-06 10:38:27,816:INFO:Starting cross validation
2024-06-06 10:38:27,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:29,753:INFO:Calculating mean and std
2024-06-06 10:38:29,755:INFO:Creating metrics dataframe
2024-06-06 10:38:29,761:INFO:Uploading results into container
2024-06-06 10:38:29,762:INFO:Uploading model into container now
2024-06-06 10:38:29,763:INFO:_master_model_container: 19
2024-06-06 10:38:29,763:INFO:_display_container: 3
2024-06-06 10:38:29,764:INFO:LGBMRegressor(n_jobs=-1, random_state=6691)
2024-06-06 10:38:29,765:INFO:create_model() successfully completed......................................
2024-06-06 10:38:29,876:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:29,876:INFO:Creating metrics dataframe
2024-06-06 10:38:29,899:INFO:Initializing Dummy Regressor
2024-06-06 10:38:29,899:INFO:Total runtime is 2.201180748144786 minutes
2024-06-06 10:38:29,905:INFO:SubProcess create_model() called ==================================
2024-06-06 10:38:29,905:INFO:Initializing create_model()
2024-06-06 10:38:29,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002050629C390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:29,906:INFO:Checking exceptions
2024-06-06 10:38:29,907:INFO:Importing libraries
2024-06-06 10:38:29,907:INFO:Copying training dataset
2024-06-06 10:38:29,924:INFO:Defining folds
2024-06-06 10:38:29,924:INFO:Declaring metric variables
2024-06-06 10:38:29,934:INFO:Importing untrained model
2024-06-06 10:38:29,941:INFO:Dummy Regressor Imported successfully
2024-06-06 10:38:29,977:INFO:Starting cross validation
2024-06-06 10:38:29,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:38:30,341:INFO:Calculating mean and std
2024-06-06 10:38:30,342:INFO:Creating metrics dataframe
2024-06-06 10:38:30,347:INFO:Uploading results into container
2024-06-06 10:38:30,349:INFO:Uploading model into container now
2024-06-06 10:38:30,351:INFO:_master_model_container: 20
2024-06-06 10:38:30,351:INFO:_display_container: 3
2024-06-06 10:38:30,353:INFO:DummyRegressor()
2024-06-06 10:38:30,354:INFO:create_model() successfully completed......................................
2024-06-06 10:38:30,475:INFO:SubProcess create_model() end ==================================
2024-06-06 10:38:30,476:INFO:Creating metrics dataframe
2024-06-06 10:38:30,512:INFO:Initializing create_model()
2024-06-06 10:38:30,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=LGBMRegressor(n_jobs=-1, random_state=6691), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:38:30,513:INFO:Checking exceptions
2024-06-06 10:38:30,516:INFO:Importing libraries
2024-06-06 10:38:30,516:INFO:Copying training dataset
2024-06-06 10:38:30,536:INFO:Defining folds
2024-06-06 10:38:30,536:INFO:Declaring metric variables
2024-06-06 10:38:30,537:INFO:Importing untrained model
2024-06-06 10:38:30,538:INFO:Declaring custom model
2024-06-06 10:38:30,539:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-06 10:38:30,541:INFO:Cross validation set to False
2024-06-06 10:38:30,542:INFO:Fitting Model
2024-06-06 10:38:30,630:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-06 10:38:30,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002465 seconds.
2024-06-06 10:38:30,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-06 10:38:30,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-06 10:38:30,640:INFO:[LightGBM] [Info] Total Bins 874
2024-06-06 10:38:30,641:INFO:[LightGBM] [Info] Number of data points in the train set: 25515, number of used features: 33
2024-06-06 10:38:30,641:INFO:[LightGBM] [Info] Start training from score 4.836292
2024-06-06 10:38:30,801:INFO:LGBMRegressor(n_jobs=-1, random_state=6691)
2024-06-06 10:38:30,802:INFO:create_model() successfully completed......................................
2024-06-06 10:38:30,971:INFO:_master_model_container: 20
2024-06-06 10:38:30,972:INFO:_display_container: 3
2024-06-06 10:38:30,973:INFO:LGBMRegressor(n_jobs=-1, random_state=6691)
2024-06-06 10:38:30,973:INFO:compare_models() successfully completed......................................
2024-06-06 10:39:14,698:INFO:Initializing plot_model()
2024-06-06 10:39:14,701:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=LGBMRegressor(n_jobs=-1, random_state=6691), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-06 10:39:14,703:INFO:Checking exceptions
2024-06-06 10:39:14,715:INFO:Preloading libraries
2024-06-06 10:39:14,736:INFO:Copying training dataset
2024-06-06 10:39:14,737:INFO:Plot type: residuals
2024-06-06 10:39:15,128:INFO:Fitting Model
2024-06-06 10:39:15,277:INFO:Scoring test/hold-out set
2024-06-06 10:39:16,588:INFO:Visual Rendered Successfully
2024-06-06 10:39:16,715:INFO:plot_model() successfully completed......................................
2024-06-06 10:39:16,717:INFO:Initializing plot_model()
2024-06-06 10:39:16,725:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020504BCBC90>, estimator=LGBMRegressor(n_jobs=-1, random_state=6691), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-06 10:39:16,725:INFO:Checking exceptions
2024-06-06 10:39:16,736:INFO:Preloading libraries
2024-06-06 10:39:16,757:INFO:Copying training dataset
2024-06-06 10:39:16,758:INFO:Plot type: error
2024-06-06 10:39:16,974:INFO:Fitting Model
2024-06-06 10:39:16,975:INFO:Scoring test/hold-out set
2024-06-06 10:39:17,744:INFO:Visual Rendered Successfully
2024-06-06 10:39:17,872:INFO:plot_model() successfully completed......................................
2024-06-06 10:43:08,667:INFO:PyCaret RegressionExperiment
2024-06-06 10:43:08,669:INFO:Logging name: reg-default-name
2024-06-06 10:43:08,670:INFO:ML Usecase: MLUsecase.REGRESSION
2024-06-06 10:43:08,670:INFO:version 3.3.2
2024-06-06 10:43:08,683:INFO:Initializing setup()
2024-06-06 10:43:08,686:INFO:self.USI: 3a62
2024-06-06 10:43:08,687:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'transform_target_param', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'X_test'}
2024-06-06 10:43:08,688:INFO:Checking environment
2024-06-06 10:43:08,688:INFO:python_version: 3.11.5
2024-06-06 10:43:08,689:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 10:43:08,691:INFO:machine: AMD64
2024-06-06 10:43:08,691:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 10:43:08,692:INFO:Memory: svmem(total=21420621824, available=6022115328, percent=71.9, used=15398506496, free=6022115328)
2024-06-06 10:43:08,692:INFO:Physical Core: 4
2024-06-06 10:43:08,693:INFO:Logical Core: 4
2024-06-06 10:43:08,693:INFO:Checking libraries
2024-06-06 10:43:08,694:INFO:System:
2024-06-06 10:43:08,694:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 10:43:08,695:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 10:43:08,695:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 10:43:08,696:INFO:PyCaret required dependencies:
2024-06-06 10:43:08,696:INFO:                 pip: 23.2.1
2024-06-06 10:43:08,696:INFO:          setuptools: 68.0.0
2024-06-06 10:43:08,697:INFO:             pycaret: 3.3.2
2024-06-06 10:43:08,697:INFO:             IPython: 8.20.0
2024-06-06 10:43:08,699:INFO:          ipywidgets: 8.1.2
2024-06-06 10:43:08,699:INFO:                tqdm: 4.65.0
2024-06-06 10:43:08,700:INFO:               numpy: 1.26.4
2024-06-06 10:43:08,700:INFO:              pandas: 1.5.3
2024-06-06 10:43:08,701:INFO:              jinja2: 3.1.3
2024-06-06 10:43:08,701:INFO:               scipy: 1.11.4
2024-06-06 10:43:08,702:INFO:              joblib: 1.2.0
2024-06-06 10:43:08,702:INFO:             sklearn: 1.4.2
2024-06-06 10:43:08,703:INFO:                pyod: 2.0.0
2024-06-06 10:43:08,703:INFO:            imblearn: 0.12.3
2024-06-06 10:43:08,703:INFO:   category_encoders: 2.6.3
2024-06-06 10:43:08,704:INFO:            lightgbm: 4.3.0
2024-06-06 10:43:08,704:INFO:               numba: 0.59.1
2024-06-06 10:43:08,704:INFO:            requests: 2.31.0
2024-06-06 10:43:08,705:INFO:          matplotlib: 3.7.5
2024-06-06 10:43:08,707:INFO:          scikitplot: 0.3.7
2024-06-06 10:43:08,708:INFO:         yellowbrick: 1.5
2024-06-06 10:43:08,708:INFO:              plotly: 5.19.0
2024-06-06 10:43:08,708:INFO:    plotly-resampler: Not installed
2024-06-06 10:43:08,708:INFO:             kaleido: 0.2.1
2024-06-06 10:43:08,709:INFO:           schemdraw: 0.15
2024-06-06 10:43:08,709:INFO:         statsmodels: 0.14.0
2024-06-06 10:43:08,709:INFO:              sktime: 0.26.0
2024-06-06 10:43:08,710:INFO:               tbats: 1.1.3
2024-06-06 10:43:08,710:INFO:            pmdarima: 2.0.4
2024-06-06 10:43:08,710:INFO:              psutil: 5.9.0
2024-06-06 10:43:08,711:INFO:          markupsafe: 2.1.3
2024-06-06 10:43:08,712:INFO:             pickle5: Not installed
2024-06-06 10:43:08,712:INFO:         cloudpickle: 2.2.1
2024-06-06 10:43:08,712:INFO:         deprecation: 2.1.0
2024-06-06 10:43:08,712:INFO:              xxhash: 2.0.2
2024-06-06 10:43:08,713:INFO:           wurlitzer: Not installed
2024-06-06 10:43:08,713:INFO:PyCaret optional dependencies:
2024-06-06 10:43:08,714:INFO:                shap: Not installed
2024-06-06 10:43:08,714:INFO:           interpret: Not installed
2024-06-06 10:43:08,714:INFO:                umap: Not installed
2024-06-06 10:43:08,715:INFO:     ydata_profiling: Not installed
2024-06-06 10:43:08,715:INFO:  explainerdashboard: Not installed
2024-06-06 10:43:08,716:INFO:             autoviz: Not installed
2024-06-06 10:43:08,716:INFO:           fairlearn: Not installed
2024-06-06 10:43:08,716:INFO:          deepchecks: Not installed
2024-06-06 10:43:08,716:INFO:             xgboost: 2.0.3
2024-06-06 10:43:08,717:INFO:            catboost: Not installed
2024-06-06 10:43:08,717:INFO:              kmodes: Not installed
2024-06-06 10:43:08,717:INFO:             mlxtend: Not installed
2024-06-06 10:43:08,717:INFO:       statsforecast: Not installed
2024-06-06 10:43:08,718:INFO:        tune_sklearn: Not installed
2024-06-06 10:43:08,718:INFO:                 ray: Not installed
2024-06-06 10:43:08,718:INFO:            hyperopt: Not installed
2024-06-06 10:43:08,718:INFO:              optuna: Not installed
2024-06-06 10:43:08,718:INFO:               skopt: Not installed
2024-06-06 10:43:08,719:INFO:              mlflow: Not installed
2024-06-06 10:43:08,719:INFO:              gradio: Not installed
2024-06-06 10:43:08,719:INFO:             fastapi: Not installed
2024-06-06 10:43:08,719:INFO:             uvicorn: Not installed
2024-06-06 10:43:08,720:INFO:              m2cgen: Not installed
2024-06-06 10:43:08,721:INFO:           evidently: Not installed
2024-06-06 10:43:08,722:INFO:               fugue: Not installed
2024-06-06 10:43:08,722:INFO:           streamlit: Not installed
2024-06-06 10:43:08,723:INFO:             prophet: Not installed
2024-06-06 10:43:08,724:INFO:None
2024-06-06 10:43:08,724:INFO:Set up data.
2024-06-06 10:43:08,768:INFO:Set up folding strategy.
2024-06-06 10:43:08,769:INFO:Set up train/test split.
2024-06-06 10:43:08,787:INFO:Set up index.
2024-06-06 10:43:08,788:INFO:Assigning column types.
2024-06-06 10:43:08,803:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 10:43:08,804:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 10:43:08,813:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:43:08,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:08,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,075:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:09,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:09,080:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,089:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,098:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,287:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:09,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:09,293:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-06-06 10:43:09,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,496:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:09,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:09,509:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,701:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:09,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:09,707:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-06-06 10:43:09,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:09,907:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:09,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:09,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,116:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:10,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:10,122:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-06-06 10:43:10,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,326:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:10,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:10,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,542:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:10,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:10,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 10:43:10,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,753:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:10,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:10,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 10:43:10,961:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:10,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:10,970:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-06-06 10:43:11,167:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:11,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:11,370:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:11,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:11,377:INFO:Preparing preprocessing pipeline...
2024-06-06 10:43:11,377:INFO:Set up simple imputation.
2024-06-06 10:43:11,380:INFO:Set up column name cleaning.
2024-06-06 10:43:11,455:INFO:Finished creating preprocessing pipeline.
2024-06-06 10:43:11,463:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['ID', 'FLAG_CARRO', 'FLAG_IMOVEL',
                                             'QTD_FILHOS', 'GANHO_ANUAL',
                                             'IDADE', 'DIAS_TRABALHADOS',
                                             'FLAG_CELULAR', 'FLAG_CELULAR_EMP',
                                             'FLAG_EMAIL', 'QTD_FAMILIARES',
                                             'F', 'M', 'Civil marriage',
                                             'Married', 'Separated',
                                             'Single / not married', '...
                                             'Student', 'Working',
                                             'Co-op apartment',
                                             'House / apartment',
                                             'Municipal apartment',
                                             'Office apartment',
                                             'Rented apartment', 'With parents',
                                             'Academic degree', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-06-06 10:43:11,464:INFO:Creating final display dataframe.
2024-06-06 10:43:11,686:INFO:Setup _display_container:                     Description             Value
0                    Session id              2614
1                        Target            STATUS
2                   Target type        Regression
3           Original data shape       (36451, 36)
4        Transformed data shape       (36451, 36)
5   Transformed train set shape       (25515, 36)
6    Transformed test set shape       (10936, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3a62
2024-06-06 10:43:11,907:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:11,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:12,128:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:43:12,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:43:12,134:INFO:setup() successfully completed in 3.48s...............
2024-06-06 10:44:06,494:INFO:PyCaret ClassificationExperiment
2024-06-06 10:44:06,506:INFO:Logging name: clf-default-name
2024-06-06 10:44:06,507:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-06 10:44:06,511:INFO:version 3.3.2
2024-06-06 10:44:06,511:INFO:Initializing setup()
2024-06-06 10:44:06,512:INFO:self.USI: 3d3a
2024-06-06 10:44:06,514:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'fix_imbalance', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'is_multiclass', 'X_test'}
2024-06-06 10:44:06,515:INFO:Checking environment
2024-06-06 10:44:06,515:INFO:python_version: 3.11.5
2024-06-06 10:44:06,515:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 10:44:06,515:INFO:machine: AMD64
2024-06-06 10:44:06,516:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 10:44:06,516:INFO:Memory: svmem(total=21420621824, available=6772731904, percent=68.4, used=14647889920, free=6772731904)
2024-06-06 10:44:06,516:INFO:Physical Core: 4
2024-06-06 10:44:06,516:INFO:Logical Core: 4
2024-06-06 10:44:06,517:INFO:Checking libraries
2024-06-06 10:44:06,517:INFO:System:
2024-06-06 10:44:06,517:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 10:44:06,517:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 10:44:06,517:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 10:44:06,518:INFO:PyCaret required dependencies:
2024-06-06 10:44:06,518:INFO:                 pip: 23.2.1
2024-06-06 10:44:06,518:INFO:          setuptools: 68.0.0
2024-06-06 10:44:06,518:INFO:             pycaret: 3.3.2
2024-06-06 10:44:06,518:INFO:             IPython: 8.20.0
2024-06-06 10:44:06,519:INFO:          ipywidgets: 8.1.2
2024-06-06 10:44:06,519:INFO:                tqdm: 4.65.0
2024-06-06 10:44:06,519:INFO:               numpy: 1.26.4
2024-06-06 10:44:06,519:INFO:              pandas: 1.5.3
2024-06-06 10:44:06,520:INFO:              jinja2: 3.1.3
2024-06-06 10:44:06,520:INFO:               scipy: 1.11.4
2024-06-06 10:44:06,520:INFO:              joblib: 1.2.0
2024-06-06 10:44:06,520:INFO:             sklearn: 1.4.2
2024-06-06 10:44:06,520:INFO:                pyod: 2.0.0
2024-06-06 10:44:06,521:INFO:            imblearn: 0.12.3
2024-06-06 10:44:06,521:INFO:   category_encoders: 2.6.3
2024-06-06 10:44:06,521:INFO:            lightgbm: 4.3.0
2024-06-06 10:44:06,521:INFO:               numba: 0.59.1
2024-06-06 10:44:06,521:INFO:            requests: 2.31.0
2024-06-06 10:44:06,522:INFO:          matplotlib: 3.7.5
2024-06-06 10:44:06,522:INFO:          scikitplot: 0.3.7
2024-06-06 10:44:06,522:INFO:         yellowbrick: 1.5
2024-06-06 10:44:06,522:INFO:              plotly: 5.19.0
2024-06-06 10:44:06,522:INFO:    plotly-resampler: Not installed
2024-06-06 10:44:06,522:INFO:             kaleido: 0.2.1
2024-06-06 10:44:06,523:INFO:           schemdraw: 0.15
2024-06-06 10:44:06,523:INFO:         statsmodels: 0.14.0
2024-06-06 10:44:06,523:INFO:              sktime: 0.26.0
2024-06-06 10:44:06,523:INFO:               tbats: 1.1.3
2024-06-06 10:44:06,524:INFO:            pmdarima: 2.0.4
2024-06-06 10:44:06,525:INFO:              psutil: 5.9.0
2024-06-06 10:44:06,526:INFO:          markupsafe: 2.1.3
2024-06-06 10:44:06,527:INFO:             pickle5: Not installed
2024-06-06 10:44:06,527:INFO:         cloudpickle: 2.2.1
2024-06-06 10:44:06,528:INFO:         deprecation: 2.1.0
2024-06-06 10:44:06,528:INFO:              xxhash: 2.0.2
2024-06-06 10:44:06,528:INFO:           wurlitzer: Not installed
2024-06-06 10:44:06,528:INFO:PyCaret optional dependencies:
2024-06-06 10:44:06,529:INFO:                shap: Not installed
2024-06-06 10:44:06,529:INFO:           interpret: Not installed
2024-06-06 10:44:06,529:INFO:                umap: Not installed
2024-06-06 10:44:06,529:INFO:     ydata_profiling: Not installed
2024-06-06 10:44:06,530:INFO:  explainerdashboard: Not installed
2024-06-06 10:44:06,530:INFO:             autoviz: Not installed
2024-06-06 10:44:06,530:INFO:           fairlearn: Not installed
2024-06-06 10:44:06,531:INFO:          deepchecks: Not installed
2024-06-06 10:44:06,531:INFO:             xgboost: 2.0.3
2024-06-06 10:44:06,531:INFO:            catboost: Not installed
2024-06-06 10:44:06,531:INFO:              kmodes: Not installed
2024-06-06 10:44:06,532:INFO:             mlxtend: Not installed
2024-06-06 10:44:06,532:INFO:       statsforecast: Not installed
2024-06-06 10:44:06,532:INFO:        tune_sklearn: Not installed
2024-06-06 10:44:06,532:INFO:                 ray: Not installed
2024-06-06 10:44:06,532:INFO:            hyperopt: Not installed
2024-06-06 10:44:06,533:INFO:              optuna: Not installed
2024-06-06 10:44:06,533:INFO:               skopt: Not installed
2024-06-06 10:44:06,533:INFO:              mlflow: Not installed
2024-06-06 10:44:06,533:INFO:              gradio: Not installed
2024-06-06 10:44:06,533:INFO:             fastapi: Not installed
2024-06-06 10:44:06,534:INFO:             uvicorn: Not installed
2024-06-06 10:44:06,534:INFO:              m2cgen: Not installed
2024-06-06 10:44:06,534:INFO:           evidently: Not installed
2024-06-06 10:44:06,534:INFO:               fugue: Not installed
2024-06-06 10:44:06,534:INFO:           streamlit: Not installed
2024-06-06 10:44:06,535:INFO:             prophet: Not installed
2024-06-06 10:44:06,535:INFO:None
2024-06-06 10:44:06,535:INFO:Set up data.
2024-06-06 10:44:06,568:INFO:Set up folding strategy.
2024-06-06 10:44:06,568:INFO:Set up train/test split.
2024-06-06 10:44:06,599:INFO:Set up index.
2024-06-06 10:44:06,600:INFO:Assigning column types.
2024-06-06 10:44:06,614:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 10:44:06,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:44:06,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:44:06,759:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:06,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:06,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:44:06,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:44:06,902:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:06,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:06,908:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 10:44:06,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:44:07,047:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:07,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:07,142:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:44:07,197:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:07,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:07,202:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-06 10:44:07,338:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:07,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:07,486:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:07,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:07,493:INFO:Preparing preprocessing pipeline...
2024-06-06 10:44:07,500:INFO:Set up simple imputation.
2024-06-06 10:44:07,502:INFO:Set up column name cleaning.
2024-06-06 10:44:07,591:INFO:Finished creating preprocessing pipeline.
2024-06-06 10:44:07,600:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['ID', 'FLAG_CARRO', 'FLAG_IMOVEL',
                                             'QTD_FILHOS', 'GANHO_ANUAL',
                                             'IDADE', 'DIAS_TRABALHADOS',
                                             'FLAG_CELULAR', 'FLAG_CELULAR_EMP',
                                             'FLAG_EMAIL', 'QTD_FAMILIARES',
                                             'F', 'M', 'Civil marriage',
                                             'Married', 'Separated',
                                             'Single /...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-06-06 10:44:07,601:INFO:Creating final display dataframe.
2024-06-06 10:44:07,850:INFO:Setup _display_container:                     Description             Value
0                    Session id              4430
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape       (36451, 36)
4        Transformed data shape       (36451, 36)
5   Transformed train set shape       (25515, 36)
6    Transformed test set shape       (10936, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3d3a
2024-06-06 10:44:08,000:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:08,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:08,142:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:44:08,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:44:08,149:INFO:setup() successfully completed in 1.67s...............
2024-06-06 10:45:18,395:INFO:Initializing compare_models()
2024-06-06 10:45:18,396:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, include=['lr', 'dt', 'rf', 'knn', 'svm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, 'include': ['lr', 'dt', 'rf', 'knn', 'svm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-06 10:45:18,397:INFO:Checking exceptions
2024-06-06 10:45:18,417:INFO:Preparing display monitor
2024-06-06 10:45:18,478:INFO:Initializing Logistic Regression
2024-06-06 10:45:18,479:INFO:Total runtime is 1.6637643178304036e-05 minutes
2024-06-06 10:45:18,487:INFO:SubProcess create_model() called ==================================
2024-06-06 10:45:18,491:INFO:Initializing create_model()
2024-06-06 10:45:18,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:45:18,498:INFO:Checking exceptions
2024-06-06 10:45:18,501:INFO:Importing libraries
2024-06-06 10:45:18,502:INFO:Copying training dataset
2024-06-06 10:45:18,540:INFO:Defining folds
2024-06-06 10:45:18,541:INFO:Declaring metric variables
2024-06-06 10:45:18,552:INFO:Importing untrained model
2024-06-06 10:45:18,564:INFO:Logistic Regression Imported successfully
2024-06-06 10:45:18,581:INFO:Starting cross validation
2024-06-06 10:45:18,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:45:18,606:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-06-06 10:45:40,006:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:40,009:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:40,034:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:40,037:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:40,047:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:40,081:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:40,110:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:40,121:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:40,528:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:40,573:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:40,601:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:57,036:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:57,058:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:57,069:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:57,190:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:57,256:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:57,264:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:57,274:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:57,285:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:45:57,852:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:45:57,874:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:45:57,882:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:09,147:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:46:09,167:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:09,178:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:09,314:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:46:09,331:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:09,340:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:09,350:INFO:Calculating mean and std
2024-06-06 10:46:09,352:INFO:Creating metrics dataframe
2024-06-06 10:46:09,358:INFO:Uploading results into container
2024-06-06 10:46:09,359:INFO:Uploading model into container now
2024-06-06 10:46:09,361:INFO:_master_model_container: 1
2024-06-06 10:46:09,361:INFO:_display_container: 2
2024-06-06 10:46:09,365:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4430, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-06 10:46:09,365:INFO:create_model() successfully completed......................................
2024-06-06 10:46:09,503:INFO:SubProcess create_model() end ==================================
2024-06-06 10:46:09,506:INFO:Creating metrics dataframe
2024-06-06 10:46:09,520:INFO:Initializing Decision Tree Classifier
2024-06-06 10:46:09,526:INFO:Total runtime is 0.8508055965105692 minutes
2024-06-06 10:46:09,531:INFO:SubProcess create_model() called ==================================
2024-06-06 10:46:09,532:INFO:Initializing create_model()
2024-06-06 10:46:09,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:46:09,533:INFO:Checking exceptions
2024-06-06 10:46:09,533:INFO:Importing libraries
2024-06-06 10:46:09,534:INFO:Copying training dataset
2024-06-06 10:46:09,560:INFO:Defining folds
2024-06-06 10:46:09,561:INFO:Declaring metric variables
2024-06-06 10:46:09,565:INFO:Importing untrained model
2024-06-06 10:46:09,575:INFO:Decision Tree Classifier Imported successfully
2024-06-06 10:46:09,585:INFO:Starting cross validation
2024-06-06 10:46:09,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:46:09,627:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-06-06 10:46:10,288:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:10,324:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:10,339:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:10,948:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

at the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:10,957:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:10,997:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:11,006:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:11,378:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:11,383:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:11,384:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:11,387:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:11,405:INFO:Calculating mean and std
2024-06-06 10:46:11,407:INFO:Creating metrics dataframe
2024-06-06 10:46:11,414:INFO:Uploading results into container
2024-06-06 10:46:11,416:INFO:Uploading model into container now
2024-06-06 10:46:11,417:INFO:_master_model_container: 2
2024-06-06 10:46:11,417:INFO:_display_container: 2
2024-06-06 10:46:11,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4430, splitter='best')
2024-06-06 10:46:11,418:INFO:create_model() successfully completed......................................
2024-06-06 10:46:11,539:INFO:SubProcess create_model() end ==================================
2024-06-06 10:46:11,540:INFO:Creating metrics dataframe
2024-06-06 10:46:11,554:INFO:Initializing Random Forest Classifier
2024-06-06 10:46:11,554:INFO:Total runtime is 0.8846080780029296 minutes
2024-06-06 10:46:11,559:INFO:SubProcess create_model() called ==================================
2024-06-06 10:46:11,560:INFO:Initializing create_model()
2024-06-06 10:46:11,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:46:11,562:INFO:Checking exceptions
2024-06-06 10:46:11,563:INFO:Importing libraries
2024-06-06 10:46:11,563:INFO:Copying training dataset
2024-06-06 10:46:11,584:INFO:Defining folds
2024-06-06 10:46:11,584:INFO:Declaring metric variables
2024-06-06 10:46:11,591:INFO:Importing untrained model
2024-06-06 10:46:11,601:INFO:Random Forest Classifier Imported successfully
2024-06-06 10:46:11,614:INFO:Starting cross validation
2024-06-06 10:46:11,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:46:11,621:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-06-06 10:46:17,976:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:17,993:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:17,999:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:18,048:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:18,058:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:18,174:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:25,271:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:25,296:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:25,478:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:25,495:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:25,713:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:28,548:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:28,581:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:28,588:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:28,600:INFO:Calculating mean and std
2024-06-06 10:46:28,601:INFO:Creating metrics dataframe
2024-06-06 10:46:28,608:INFO:Uploading results into container
2024-06-06 10:46:28,612:INFO:Uploading model into container now
2024-06-06 10:46:28,613:INFO:_master_model_container: 3
2024-06-06 10:46:28,613:INFO:_display_container: 2
2024-06-06 10:46:28,614:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4430, verbose=0,
                       warm_start=False)
2024-06-06 10:46:28,614:INFO:create_model() successfully completed......................................
2024-06-06 10:46:28,739:INFO:SubProcess create_model() end ==================================
2024-06-06 10:46:28,739:INFO:Creating metrics dataframe
2024-06-06 10:46:28,756:INFO:Initializing K Neighbors Classifier
2024-06-06 10:46:28,756:INFO:Total runtime is 1.1713128368059793 minutes
2024-06-06 10:46:28,763:INFO:SubProcess create_model() called ==================================
2024-06-06 10:46:28,763:INFO:Initializing create_model()
2024-06-06 10:46:28,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:46:28,765:INFO:Checking exceptions
2024-06-06 10:46:28,765:INFO:Importing libraries
2024-06-06 10:46:28,765:INFO:Copying training dataset
2024-06-06 10:46:28,790:INFO:Defining folds
2024-06-06 10:46:28,791:INFO:Declaring metric variables
2024-06-06 10:46:28,798:INFO:Importing untrained model
2024-06-06 10:46:28,805:INFO:K Neighbors Classifier Imported successfully
2024-06-06 10:46:28,822:INFO:Starting cross validation
2024-06-06 10:46:28,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:46:28,832:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-06-06 10:46:30,801:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:30,854:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:30,866:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:30,875:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:30,894:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:31,016:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:32,668:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:32,704:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:32,839:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:32,849:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:33,933:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:33,938:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-06-06 10:46:33,943:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:33,946:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:33,958:INFO:Calculating mean and std
2024-06-06 10:46:33,959:INFO:Creating metrics dataframe
2024-06-06 10:46:33,966:INFO:Uploading results into container
2024-06-06 10:46:33,967:INFO:Uploading model into container now
2024-06-06 10:46:33,968:INFO:_master_model_container: 4
2024-06-06 10:46:33,969:INFO:_display_container: 2
2024-06-06 10:46:33,969:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-06 10:46:33,969:INFO:create_model() successfully completed......................................
2024-06-06 10:46:34,098:INFO:SubProcess create_model() end ==================================
2024-06-06 10:46:34,099:INFO:Creating metrics dataframe
2024-06-06 10:46:34,115:INFO:Initializing SVM - Linear Kernel
2024-06-06 10:46:34,116:INFO:Total runtime is 1.2606361746788024 minutes
2024-06-06 10:46:34,120:INFO:SubProcess create_model() called ==================================
2024-06-06 10:46:34,121:INFO:Initializing create_model()
2024-06-06 10:46:34,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:46:34,122:INFO:Checking exceptions
2024-06-06 10:46:34,123:INFO:Importing libraries
2024-06-06 10:46:34,124:INFO:Copying training dataset
2024-06-06 10:46:34,146:INFO:Defining folds
2024-06-06 10:46:34,146:INFO:Declaring metric variables
2024-06-06 10:46:34,153:INFO:Importing untrained model
2024-06-06 10:46:34,160:INFO:SVM - Linear Kernel Imported successfully
2024-06-06 10:46:34,174:INFO:Starting cross validation
2024-06-06 10:46:34,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:46:34,183:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-06-06 10:46:43,187:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:43,277:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:43,373:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:43,453:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:44,024:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:44,253:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:44,333:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:44,418:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:53,526:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:53,678:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:54,098:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:54,107:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:54,160:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:54,240:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:54,715:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:54,801:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:58,665:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:58,672:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:59,431:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:46:59,440:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:46:59,454:INFO:Calculating mean and std
2024-06-06 10:46:59,456:INFO:Creating metrics dataframe
2024-06-06 10:46:59,461:INFO:Uploading results into container
2024-06-06 10:46:59,462:INFO:Uploading model into container now
2024-06-06 10:46:59,465:INFO:_master_model_container: 5
2024-06-06 10:46:59,465:INFO:_display_container: 2
2024-06-06 10:46:59,468:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4430, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-06-06 10:46:59,468:INFO:create_model() successfully completed......................................
2024-06-06 10:46:59,611:INFO:SubProcess create_model() end ==================================
2024-06-06 10:46:59,611:INFO:Creating metrics dataframe
2024-06-06 10:46:59,650:INFO:Initializing create_model()
2024-06-06 10:46:59,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002050529AE90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4430, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:46:59,700:INFO:Checking exceptions
2024-06-06 10:46:59,703:INFO:Importing libraries
2024-06-06 10:46:59,713:INFO:Copying training dataset
2024-06-06 10:46:59,734:INFO:Defining folds
2024-06-06 10:46:59,734:INFO:Declaring metric variables
2024-06-06 10:46:59,735:INFO:Importing untrained model
2024-06-06 10:46:59,735:INFO:Declaring custom model
2024-06-06 10:46:59,736:INFO:Random Forest Classifier Imported successfully
2024-06-06 10:46:59,738:INFO:Cross validation set to False
2024-06-06 10:46:59,738:INFO:Fitting Model
2024-06-06 10:47:01,559:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4430, verbose=0,
                       warm_start=False)
2024-06-06 10:47:01,560:INFO:create_model() successfully completed......................................
2024-06-06 10:47:01,738:INFO:_master_model_container: 5
2024-06-06 10:47:01,738:INFO:_display_container: 2
2024-06-06 10:47:01,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4430, verbose=0,
                       warm_start=False)
2024-06-06 10:47:01,740:INFO:compare_models() successfully completed......................................
2024-06-06 10:50:04,721:INFO:PyCaret ClassificationExperiment
2024-06-06 10:50:04,723:INFO:Logging name: clf-default-name
2024-06-06 10:50:04,723:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-06 10:50:04,723:INFO:version 3.3.2
2024-06-06 10:50:04,723:INFO:Initializing setup()
2024-06-06 10:50:04,724:INFO:self.USI: 69c4
2024-06-06 10:50:04,724:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'fix_imbalance', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'is_multiclass', 'X_test'}
2024-06-06 10:50:04,724:INFO:Checking environment
2024-06-06 10:50:04,724:INFO:python_version: 3.11.5
2024-06-06 10:50:04,724:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 10:50:04,727:INFO:machine: AMD64
2024-06-06 10:50:04,727:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 10:50:04,727:INFO:Memory: svmem(total=21420621824, available=5261697024, percent=75.4, used=16158924800, free=5261697024)
2024-06-06 10:50:04,728:INFO:Physical Core: 4
2024-06-06 10:50:04,728:INFO:Logical Core: 4
2024-06-06 10:50:04,728:INFO:Checking libraries
2024-06-06 10:50:04,728:INFO:System:
2024-06-06 10:50:04,729:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 10:50:04,729:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 10:50:04,729:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 10:50:04,729:INFO:PyCaret required dependencies:
2024-06-06 10:50:04,730:INFO:                 pip: 23.2.1
2024-06-06 10:50:04,730:INFO:          setuptools: 68.0.0
2024-06-06 10:50:04,730:INFO:             pycaret: 3.3.2
2024-06-06 10:50:04,730:INFO:             IPython: 8.20.0
2024-06-06 10:50:04,731:INFO:          ipywidgets: 8.1.2
2024-06-06 10:50:04,731:INFO:                tqdm: 4.65.0
2024-06-06 10:50:04,731:INFO:               numpy: 1.26.4
2024-06-06 10:50:04,731:INFO:              pandas: 1.5.3
2024-06-06 10:50:04,731:INFO:              jinja2: 3.1.3
2024-06-06 10:50:04,731:INFO:               scipy: 1.11.4
2024-06-06 10:50:04,732:INFO:              joblib: 1.2.0
2024-06-06 10:50:04,732:INFO:             sklearn: 1.4.2
2024-06-06 10:50:04,732:INFO:                pyod: 2.0.0
2024-06-06 10:50:04,732:INFO:            imblearn: 0.12.3
2024-06-06 10:50:04,732:INFO:   category_encoders: 2.6.3
2024-06-06 10:50:04,733:INFO:            lightgbm: 4.3.0
2024-06-06 10:50:04,733:INFO:               numba: 0.59.1
2024-06-06 10:50:04,733:INFO:            requests: 2.31.0
2024-06-06 10:50:04,733:INFO:          matplotlib: 3.7.5
2024-06-06 10:50:04,733:INFO:          scikitplot: 0.3.7
2024-06-06 10:50:04,734:INFO:         yellowbrick: 1.5
2024-06-06 10:50:04,734:INFO:              plotly: 5.19.0
2024-06-06 10:50:04,734:INFO:    plotly-resampler: Not installed
2024-06-06 10:50:04,734:INFO:             kaleido: 0.2.1
2024-06-06 10:50:04,734:INFO:           schemdraw: 0.15
2024-06-06 10:50:04,734:INFO:         statsmodels: 0.14.0
2024-06-06 10:50:04,735:INFO:              sktime: 0.26.0
2024-06-06 10:50:04,735:INFO:               tbats: 1.1.3
2024-06-06 10:50:04,735:INFO:            pmdarima: 2.0.4
2024-06-06 10:50:04,735:INFO:              psutil: 5.9.0
2024-06-06 10:50:04,735:INFO:          markupsafe: 2.1.3
2024-06-06 10:50:04,736:INFO:             pickle5: Not installed
2024-06-06 10:50:04,736:INFO:         cloudpickle: 2.2.1
2024-06-06 10:50:04,736:INFO:         deprecation: 2.1.0
2024-06-06 10:50:04,736:INFO:              xxhash: 2.0.2
2024-06-06 10:50:04,736:INFO:           wurlitzer: Not installed
2024-06-06 10:50:04,737:INFO:PyCaret optional dependencies:
2024-06-06 10:50:04,737:INFO:                shap: Not installed
2024-06-06 10:50:04,737:INFO:           interpret: Not installed
2024-06-06 10:50:04,737:INFO:                umap: Not installed
2024-06-06 10:50:04,737:INFO:     ydata_profiling: Not installed
2024-06-06 10:50:04,738:INFO:  explainerdashboard: Not installed
2024-06-06 10:50:04,738:INFO:             autoviz: Not installed
2024-06-06 10:50:04,738:INFO:           fairlearn: Not installed
2024-06-06 10:50:04,738:INFO:          deepchecks: Not installed
2024-06-06 10:50:04,738:INFO:             xgboost: 2.0.3
2024-06-06 10:50:04,738:INFO:            catboost: Not installed
2024-06-06 10:50:04,739:INFO:              kmodes: Not installed
2024-06-06 10:50:04,739:INFO:             mlxtend: Not installed
2024-06-06 10:50:04,739:INFO:       statsforecast: Not installed
2024-06-06 10:50:04,739:INFO:        tune_sklearn: Not installed
2024-06-06 10:50:04,739:INFO:                 ray: Not installed
2024-06-06 10:50:04,740:INFO:            hyperopt: Not installed
2024-06-06 10:50:04,740:INFO:              optuna: Not installed
2024-06-06 10:50:04,740:INFO:               skopt: Not installed
2024-06-06 10:50:04,740:INFO:              mlflow: Not installed
2024-06-06 10:50:04,740:INFO:              gradio: Not installed
2024-06-06 10:50:04,741:INFO:             fastapi: Not installed
2024-06-06 10:50:04,741:INFO:             uvicorn: Not installed
2024-06-06 10:50:04,741:INFO:              m2cgen: Not installed
2024-06-06 10:50:04,741:INFO:           evidently: Not installed
2024-06-06 10:50:04,741:INFO:               fugue: Not installed
2024-06-06 10:50:04,743:INFO:           streamlit: Not installed
2024-06-06 10:50:04,744:INFO:             prophet: Not installed
2024-06-06 10:50:04,744:INFO:None
2024-06-06 10:50:04,744:INFO:Set up data.
2024-06-06 10:50:05,509:INFO:Set up folding strategy.
2024-06-06 10:50:05,509:INFO:Set up train/test split.
2024-06-06 10:50:06,080:INFO:Set up index.
2024-06-06 10:50:06,112:INFO:Assigning column types.
2024-06-06 10:50:06,303:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 10:50:06,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,442:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:06,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:06,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,617:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:06,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:06,622:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 10:50:06,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,758:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:06,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:06,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 10:50:06,898:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:06,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:06,905:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-06 10:50:07,035:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:07,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:07,166:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:07,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:07,175:INFO:Preparing preprocessing pipeline...
2024-06-06 10:50:07,208:INFO:Set up simple imputation.
2024-06-06 10:50:07,235:INFO:Set up column name cleaning.
2024-06-06 10:50:08,445:INFO:Finished creating preprocessing pipeline.
2024-06-06 10:50:08,452:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['ID', 'FLAG_CARRO', 'FLAG_IMOVEL',
                                             'QTD_FILHOS', 'GANHO_ANUAL',
                                             'IDADE', 'DIAS_TRABALHADOS',
                                             'FLAG_CELULAR', 'FLAG_CELULAR_EMP',
                                             'FLAG_EMAIL', 'QTD_FAMILIARES',
                                             'F', 'M', 'Civil marriage',
                                             'Married', 'Separated',
                                             'Single /...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-06-06 10:50:08,453:INFO:Creating final display dataframe.
2024-06-06 10:50:11,151:INFO:Setup _display_container:                     Description             Value
0                    Session id              3511
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              69c4
2024-06-06 10:50:11,304:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:11,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:11,438:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 10:50:11,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 10:50:11,446:INFO:setup() successfully completed in 6.75s...............
2024-06-06 10:50:22,605:INFO:Initializing compare_models()
2024-06-06 10:50:22,675:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-06 10:50:22,717:INFO:Checking exceptions
2024-06-06 10:50:22,925:INFO:Preparing display monitor
2024-06-06 10:50:22,964:INFO:Initializing Logistic Regression
2024-06-06 10:50:22,975:INFO:Total runtime is 0.0001833637555440267 minutes
2024-06-06 10:50:23,037:INFO:SubProcess create_model() called ==================================
2024-06-06 10:50:23,042:INFO:Initializing create_model()
2024-06-06 10:50:23,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 10:50:23,044:INFO:Checking exceptions
2024-06-06 10:50:23,044:INFO:Importing libraries
2024-06-06 10:50:23,044:INFO:Copying training dataset
2024-06-06 10:50:23,410:INFO:Defining folds
2024-06-06 10:50:23,410:INFO:Declaring metric variables
2024-06-06 10:50:23,414:INFO:Importing untrained model
2024-06-06 10:50:23,420:INFO:Logistic Regression Imported successfully
2024-06-06 10:50:23,430:INFO:Starting cross validation
2024-06-06 10:50:23,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 10:55:27,200:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:55:27,372:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:55:27,413:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:55:27,797:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:55:27,969:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:55:28,024:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:55:28,637:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:55:28,865:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:55:28,922:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 10:55:37,169:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 10:55:37,362:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 10:55:37,432:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:00:38,022:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:00:38,202:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:00:38,251:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:00:39,348:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:00:39,563:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:00:39,605:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:00:43,011:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:00:43,148:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:00:43,191:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:00:50,098:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:00:50,325:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:00:50,378:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:05:17,726:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:05:17,874:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:05:17,917:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:05:18,906:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-06 11:05:19,025:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:05:19,062:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:05:19,222:INFO:Calculating mean and std
2024-06-06 11:05:19,224:INFO:Creating metrics dataframe
2024-06-06 11:05:19,229:INFO:Uploading results into container
2024-06-06 11:05:19,231:INFO:Uploading model into container now
2024-06-06 11:05:19,232:INFO:_master_model_container: 1
2024-06-06 11:05:19,234:INFO:_display_container: 2
2024-06-06 11:05:19,238:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3511, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-06 11:05:19,239:INFO:create_model() successfully completed......................................
2024-06-06 11:05:19,380:INFO:SubProcess create_model() end ==================================
2024-06-06 11:05:19,381:INFO:Creating metrics dataframe
2024-06-06 11:05:19,396:INFO:Initializing K Neighbors Classifier
2024-06-06 11:05:19,396:INFO:Total runtime is 14.940521518389385 minutes
2024-06-06 11:05:19,401:INFO:SubProcess create_model() called ==================================
2024-06-06 11:05:19,403:INFO:Initializing create_model()
2024-06-06 11:05:19,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 11:05:19,407:INFO:Checking exceptions
2024-06-06 11:05:19,407:INFO:Importing libraries
2024-06-06 11:05:19,408:INFO:Copying training dataset
2024-06-06 11:05:19,841:INFO:Defining folds
2024-06-06 11:05:19,841:INFO:Declaring metric variables
2024-06-06 11:05:19,848:INFO:Importing untrained model
2024-06-06 11:05:19,853:INFO:K Neighbors Classifier Imported successfully
2024-06-06 11:05:19,867:INFO:Starting cross validation
2024-06-06 11:05:19,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 11:13:58,705:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:49,724:INFO:Calculating mean and std
2024-06-06 11:30:49,725:INFO:Creating metrics dataframe
2024-06-06 11:30:49,732:INFO:Uploading results into container
2024-06-06 11:30:49,740:INFO:Uploading model into container now
2024-06-06 11:30:49,742:INFO:_master_model_container: 2
2024-06-06 11:30:49,743:INFO:_display_container: 2
2024-06-06 11:30:49,745:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-06 11:30:49,746:INFO:create_model() successfully completed......................................
2024-06-06 11:30:49,871:INFO:SubProcess create_model() end ==================================
2024-06-06 11:30:49,871:INFO:Creating metrics dataframe
2024-06-06 11:30:49,886:INFO:Initializing Naive Bayes
2024-06-06 11:30:49,886:INFO:Total runtime is 40.44869708617529 minutes
2024-06-06 11:30:49,891:INFO:SubProcess create_model() called ==================================
2024-06-06 11:30:49,892:INFO:Initializing create_model()
2024-06-06 11:30:49,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 11:30:49,892:INFO:Checking exceptions
2024-06-06 11:30:49,893:INFO:Importing libraries
2024-06-06 11:30:49,893:INFO:Copying training dataset
2024-06-06 11:30:50,277:INFO:Defining folds
2024-06-06 11:30:50,277:INFO:Declaring metric variables
2024-06-06 11:30:50,287:INFO:Importing untrained model
2024-06-06 11:30:50,293:INFO:Naive Bayes Imported successfully
2024-06-06 11:30:50,306:INFO:Starting cross validation
2024-06-06 11:30:50,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 11:30:52,811:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:52,854:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:55,374:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:55,417:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:57,827:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:30:57,895:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:31:00,221:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:31:00,276:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:31:04,636:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:31:04,651:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:31:04,806:INFO:Calculating mean and std
2024-06-06 11:31:04,807:INFO:Creating metrics dataframe
2024-06-06 11:31:04,815:INFO:Uploading results into container
2024-06-06 11:31:04,822:INFO:Uploading model into container now
2024-06-06 11:31:04,822:INFO:_master_model_container: 3
2024-06-06 11:31:04,823:INFO:_display_container: 2
2024-06-06 11:31:04,823:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-06-06 11:31:04,823:INFO:create_model() successfully completed......................................
2024-06-06 11:31:04,945:INFO:SubProcess create_model() end ==================================
2024-06-06 11:31:04,945:INFO:Creating metrics dataframe
2024-06-06 11:31:04,959:INFO:Initializing Decision Tree Classifier
2024-06-06 11:31:04,960:INFO:Total runtime is 40.6999325354894 minutes
2024-06-06 11:31:04,966:INFO:SubProcess create_model() called ==================================
2024-06-06 11:31:04,966:INFO:Initializing create_model()
2024-06-06 11:31:04,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 11:31:04,967:INFO:Checking exceptions
2024-06-06 11:31:04,967:INFO:Importing libraries
2024-06-06 11:31:04,968:INFO:Copying training dataset
2024-06-06 11:31:05,341:INFO:Defining folds
2024-06-06 11:31:05,342:INFO:Declaring metric variables
2024-06-06 11:31:05,351:INFO:Importing untrained model
2024-06-06 11:31:05,359:INFO:Decision Tree Classifier Imported successfully
2024-06-06 11:31:05,372:INFO:Starting cross validation
2024-06-06 11:31:05,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 11:31:41,942:INFO:Calculating mean and std
2024-06-06 11:31:41,945:INFO:Creating metrics dataframe
2024-06-06 11:31:41,950:INFO:Uploading results into container
2024-06-06 11:31:41,951:INFO:Uploading model into container now
2024-06-06 11:31:41,953:INFO:_master_model_container: 4
2024-06-06 11:31:41,954:INFO:_display_container: 2
2024-06-06 11:31:41,954:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3511, splitter='best')
2024-06-06 11:31:41,956:INFO:create_model() successfully completed......................................
2024-06-06 11:31:42,084:INFO:SubProcess create_model() end ==================================
2024-06-06 11:31:42,084:INFO:Creating metrics dataframe
2024-06-06 11:31:42,100:INFO:Initializing SVM - Linear Kernel
2024-06-06 11:31:42,101:INFO:Total runtime is 41.31894538799922 minutes
2024-06-06 11:31:42,106:INFO:SubProcess create_model() called ==================================
2024-06-06 11:31:42,107:INFO:Initializing create_model()
2024-06-06 11:31:42,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 11:31:42,107:INFO:Checking exceptions
2024-06-06 11:31:42,108:INFO:Importing libraries
2024-06-06 11:31:42,109:INFO:Copying training dataset
2024-06-06 11:31:42,496:INFO:Defining folds
2024-06-06 11:31:42,497:INFO:Declaring metric variables
2024-06-06 11:31:42,504:INFO:Importing untrained model
2024-06-06 11:31:42,509:INFO:SVM - Linear Kernel Imported successfully
2024-06-06 11:31:42,520:INFO:Starting cross validation
2024-06-06 11:31:42,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 11:51:47,079:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 11:51:47,576:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:51:47,704:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:51:53,662:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 11:51:54,791:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:51:54,919:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:52:14,478:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 11:52:15,060:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:52:15,384:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 11:52:50,851:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 11:52:51,305:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 11:52:51,820:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:11:39,561:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:11:39,838:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:11:39,969:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:11:40,638:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:11:40,905:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:11:41,047:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:11:56,410:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:11:57,063:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:11:57,434:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:12:15,213:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:12:15,696:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:12:15,835:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:13,659:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:22:13,767:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:13,800:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:20,729:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-06-06 12:22:20,838:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:20,868:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:21,024:INFO:Calculating mean and std
2024-06-06 12:22:21,026:INFO:Creating metrics dataframe
2024-06-06 12:22:21,030:INFO:Uploading results into container
2024-06-06 12:22:21,032:INFO:Uploading model into container now
2024-06-06 12:22:21,034:INFO:_master_model_container: 5
2024-06-06 12:22:21,035:INFO:_display_container: 2
2024-06-06 12:22:21,036:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3511, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-06-06 12:22:21,041:INFO:create_model() successfully completed......................................
2024-06-06 12:22:21,162:INFO:SubProcess create_model() end ==================================
2024-06-06 12:22:21,162:INFO:Creating metrics dataframe
2024-06-06 12:22:21,177:INFO:Initializing Ridge Classifier
2024-06-06 12:22:21,178:INFO:Total runtime is 91.97022881905238 minutes
2024-06-06 12:22:21,183:INFO:SubProcess create_model() called ==================================
2024-06-06 12:22:21,184:INFO:Initializing create_model()
2024-06-06 12:22:21,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 12:22:21,185:INFO:Checking exceptions
2024-06-06 12:22:21,185:INFO:Importing libraries
2024-06-06 12:22:21,185:INFO:Copying training dataset
2024-06-06 12:22:21,560:INFO:Defining folds
2024-06-06 12:22:21,561:INFO:Declaring metric variables
2024-06-06 12:22:21,568:INFO:Importing untrained model
2024-06-06 12:22:21,574:INFO:Ridge Classifier Imported successfully
2024-06-06 12:22:21,585:INFO:Starting cross validation
2024-06-06 12:22:21,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 12:22:23,832:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:23,837:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:23,871:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:23,872:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:25,951:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:25,992:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:28,197:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:28,240:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:28,258:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:28,305:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:30,540:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:30,580:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:30,595:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:30,634:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:36,224:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:36,251:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:22:36,268:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:36,293:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:22:36,452:INFO:Calculating mean and std
2024-06-06 12:22:36,453:INFO:Creating metrics dataframe
2024-06-06 12:22:36,459:INFO:Uploading results into container
2024-06-06 12:22:36,461:INFO:Uploading model into container now
2024-06-06 12:22:36,472:INFO:_master_model_container: 6
2024-06-06 12:22:36,501:INFO:_display_container: 2
2024-06-06 12:22:36,504:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3511, solver='auto',
                tol=0.0001)
2024-06-06 12:22:36,504:INFO:create_model() successfully completed......................................
2024-06-06 12:22:36,634:INFO:SubProcess create_model() end ==================================
2024-06-06 12:22:36,635:INFO:Creating metrics dataframe
2024-06-06 12:22:36,653:INFO:Initializing Random Forest Classifier
2024-06-06 12:22:36,654:INFO:Total runtime is 92.22816475232442 minutes
2024-06-06 12:22:36,660:INFO:SubProcess create_model() called ==================================
2024-06-06 12:22:36,661:INFO:Initializing create_model()
2024-06-06 12:22:36,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 12:22:36,662:INFO:Checking exceptions
2024-06-06 12:22:36,662:INFO:Importing libraries
2024-06-06 12:22:36,663:INFO:Copying training dataset
2024-06-06 12:22:37,063:INFO:Defining folds
2024-06-06 12:22:37,063:INFO:Declaring metric variables
2024-06-06 12:22:37,072:INFO:Importing untrained model
2024-06-06 12:22:37,079:INFO:Random Forest Classifier Imported successfully
2024-06-06 12:22:37,089:INFO:Starting cross validation
2024-06-06 12:22:37,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 12:32:14,484:INFO:Calculating mean and std
2024-06-06 12:32:14,487:INFO:Creating metrics dataframe
2024-06-06 12:32:14,493:INFO:Uploading results into container
2024-06-06 12:32:14,495:INFO:Uploading model into container now
2024-06-06 12:32:14,496:INFO:_master_model_container: 7
2024-06-06 12:32:14,496:INFO:_display_container: 2
2024-06-06 12:32:14,497:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3511, verbose=0,
                       warm_start=False)
2024-06-06 12:32:14,498:INFO:create_model() successfully completed......................................
2024-06-06 12:32:14,661:INFO:SubProcess create_model() end ==================================
2024-06-06 12:32:14,662:INFO:Creating metrics dataframe
2024-06-06 12:32:14,680:INFO:Initializing Quadratic Discriminant Analysis
2024-06-06 12:32:14,681:INFO:Total runtime is 101.86194746096929 minutes
2024-06-06 12:32:14,687:INFO:SubProcess create_model() called ==================================
2024-06-06 12:32:14,688:INFO:Initializing create_model()
2024-06-06 12:32:14,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 12:32:14,690:INFO:Checking exceptions
2024-06-06 12:32:14,690:INFO:Importing libraries
2024-06-06 12:32:14,690:INFO:Copying training dataset
2024-06-06 12:32:15,120:INFO:Defining folds
2024-06-06 12:32:15,121:INFO:Declaring metric variables
2024-06-06 12:32:15,127:INFO:Importing untrained model
2024-06-06 12:32:15,134:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-06 12:32:15,146:INFO:Starting cross validation
2024-06-06 12:32:15,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 12:32:19,647:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:19,717:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:19,786:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:19,837:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:24,836:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:24,842:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:24,876:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:24,882:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:24,911:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:24,953:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:25,052:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:25,112:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:28,496:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:28,566:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:28,672:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:28,902:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:33,868:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:33,904:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:34,035:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:34,072:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:34,090:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:34,183:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:36,117:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:36,160:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-06 12:32:38,908:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:38,921:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:32:38,947:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:38,963:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:32:39,119:INFO:Calculating mean and std
2024-06-06 12:32:39,120:INFO:Creating metrics dataframe
2024-06-06 12:32:39,126:INFO:Uploading results into container
2024-06-06 12:32:39,129:INFO:Uploading model into container now
2024-06-06 12:32:39,130:INFO:_master_model_container: 8
2024-06-06 12:32:39,131:INFO:_display_container: 2
2024-06-06 12:32:39,131:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-06-06 12:32:39,132:INFO:create_model() successfully completed......................................
2024-06-06 12:32:39,269:INFO:SubProcess create_model() end ==================================
2024-06-06 12:32:39,269:INFO:Creating metrics dataframe
2024-06-06 12:32:39,287:INFO:Initializing Ada Boost Classifier
2024-06-06 12:32:39,288:INFO:Total runtime is 102.27205956776938 minutes
2024-06-06 12:32:39,293:INFO:SubProcess create_model() called ==================================
2024-06-06 12:32:39,294:INFO:Initializing create_model()
2024-06-06 12:32:39,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 12:32:39,294:INFO:Checking exceptions
2024-06-06 12:32:39,297:INFO:Importing libraries
2024-06-06 12:32:39,298:INFO:Copying training dataset
2024-06-06 12:32:39,733:INFO:Defining folds
2024-06-06 12:32:39,734:INFO:Declaring metric variables
2024-06-06 12:32:39,739:INFO:Importing untrained model
2024-06-06 12:32:39,745:INFO:Ada Boost Classifier Imported successfully
2024-06-06 12:32:39,756:INFO:Starting cross validation
2024-06-06 12:32:39,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 12:32:41,584:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:32:41,589:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:32:41,635:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:33:54,167:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:33:54,214:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:33:54,332:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:33:54,379:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:33:54,672:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:33:54,727:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:33:55,079:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:33:55,118:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:33:55,646:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:33:55,911:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:33:56,231:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:33:56,560:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:35:03,144:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:35:03,193:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:35:04,076:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:35:04,130:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:35:04,473:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:35:04,516:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:35:04,651:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:35:05,178:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:35:05,217:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:35:05,373:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-06 12:35:59,872:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:35:59,915:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:36:00,203:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 12:36:00,249:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 12:36:00,415:INFO:Calculating mean and std
2024-06-06 12:36:00,417:INFO:Creating metrics dataframe
2024-06-06 12:36:00,427:INFO:Uploading results into container
2024-06-06 12:36:00,428:INFO:Uploading model into container now
2024-06-06 12:36:00,429:INFO:_master_model_container: 9
2024-06-06 12:36:00,430:INFO:_display_container: 2
2024-06-06 12:36:00,433:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3511)
2024-06-06 12:36:00,433:INFO:create_model() successfully completed......................................
2024-06-06 12:36:00,574:INFO:SubProcess create_model() end ==================================
2024-06-06 12:36:00,574:INFO:Creating metrics dataframe
2024-06-06 12:36:00,591:INFO:Initializing Gradient Boosting Classifier
2024-06-06 12:36:00,593:INFO:Total runtime is 105.62714848518372 minutes
2024-06-06 12:36:00,600:INFO:SubProcess create_model() called ==================================
2024-06-06 12:36:00,601:INFO:Initializing create_model()
2024-06-06 12:36:00,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 12:36:00,602:INFO:Checking exceptions
2024-06-06 12:36:00,602:INFO:Importing libraries
2024-06-06 12:36:00,603:INFO:Copying training dataset
2024-06-06 12:36:01,007:INFO:Defining folds
2024-06-06 12:36:01,008:INFO:Declaring metric variables
2024-06-06 12:36:01,013:INFO:Importing untrained model
2024-06-06 12:36:01,021:INFO:Gradient Boosting Classifier Imported successfully
2024-06-06 12:36:01,029:INFO:Starting cross validation
2024-06-06 12:36:01,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 13:01:45,923:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:01:51,242:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:01:51,290:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:01:52,708:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:01:53,499:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:28:57,169:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:28:57,261:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:29:05,963:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:29:11,871:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:29:26,908:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:46:56,416:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:02,591:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:02,771:INFO:Calculating mean and std
2024-06-06 13:47:02,772:INFO:Creating metrics dataframe
2024-06-06 13:47:02,778:INFO:Uploading results into container
2024-06-06 13:47:02,779:INFO:Uploading model into container now
2024-06-06 13:47:02,780:INFO:_master_model_container: 10
2024-06-06 13:47:02,780:INFO:_display_container: 2
2024-06-06 13:47:02,781:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3511, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-06 13:47:02,782:INFO:create_model() successfully completed......................................
2024-06-06 13:47:02,901:INFO:SubProcess create_model() end ==================================
2024-06-06 13:47:02,902:INFO:Creating metrics dataframe
2024-06-06 13:47:02,920:INFO:Initializing Linear Discriminant Analysis
2024-06-06 13:47:02,920:INFO:Total runtime is 176.6659285147985 minutes
2024-06-06 13:47:02,926:INFO:SubProcess create_model() called ==================================
2024-06-06 13:47:02,926:INFO:Initializing create_model()
2024-06-06 13:47:02,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 13:47:02,927:INFO:Checking exceptions
2024-06-06 13:47:02,927:INFO:Importing libraries
2024-06-06 13:47:02,928:INFO:Copying training dataset
2024-06-06 13:47:03,284:INFO:Defining folds
2024-06-06 13:47:03,284:INFO:Declaring metric variables
2024-06-06 13:47:03,291:INFO:Importing untrained model
2024-06-06 13:47:03,295:INFO:Linear Discriminant Analysis Imported successfully
2024-06-06 13:47:03,304:INFO:Starting cross validation
2024-06-06 13:47:03,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 13:47:08,873:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:08,915:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:08,928:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:08,970:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:13,782:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:13,814:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:13,822:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:13,853:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:18,616:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:18,649:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:18,665:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:18,708:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:26,131:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:26,169:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:26,261:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:26,293:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:26,398:WARNING:c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-06-06 13:47:26,434:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:26,435:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 13:47:26,591:INFO:Calculating mean and std
2024-06-06 13:47:26,592:INFO:Creating metrics dataframe
2024-06-06 13:47:26,598:INFO:Uploading results into container
2024-06-06 13:47:26,599:INFO:Uploading model into container now
2024-06-06 13:47:26,600:INFO:_master_model_container: 11
2024-06-06 13:47:26,600:INFO:_display_container: 2
2024-06-06 13:47:26,601:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-06 13:47:26,602:INFO:create_model() successfully completed......................................
2024-06-06 13:47:26,730:INFO:SubProcess create_model() end ==================================
2024-06-06 13:47:26,730:INFO:Creating metrics dataframe
2024-06-06 13:47:26,749:INFO:Initializing Extra Trees Classifier
2024-06-06 13:47:26,749:INFO:Total runtime is 177.06307481129966 minutes
2024-06-06 13:47:26,754:INFO:SubProcess create_model() called ==================================
2024-06-06 13:47:26,755:INFO:Initializing create_model()
2024-06-06 13:47:26,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 13:47:26,756:INFO:Checking exceptions
2024-06-06 13:47:26,756:INFO:Importing libraries
2024-06-06 13:47:26,756:INFO:Copying training dataset
2024-06-06 13:47:27,140:INFO:Defining folds
2024-06-06 13:47:27,141:INFO:Declaring metric variables
2024-06-06 13:47:27,146:INFO:Importing untrained model
2024-06-06 13:47:27,152:INFO:Extra Trees Classifier Imported successfully
2024-06-06 13:47:27,161:INFO:Starting cross validation
2024-06-06 13:47:27,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 14:35:29,802:INFO:Calculating mean and std
2024-06-06 14:35:30,004:INFO:Creating metrics dataframe
2024-06-06 14:35:30,272:INFO:Uploading results into container
2024-06-06 14:35:30,293:INFO:Uploading model into container now
2024-06-06 14:35:30,314:INFO:_master_model_container: 12
2024-06-06 14:35:30,315:INFO:_display_container: 2
2024-06-06 14:35:30,344:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3511, verbose=0,
                     warm_start=False)
2024-06-06 14:35:30,345:INFO:create_model() successfully completed......................................
2024-06-06 14:35:32,226:INFO:SubProcess create_model() end ==================================
2024-06-06 14:35:32,227:INFO:Creating metrics dataframe
2024-06-06 14:35:32,274:INFO:Initializing Extreme Gradient Boosting
2024-06-06 14:35:32,275:INFO:Total runtime is 225.15517577330274 minutes
2024-06-06 14:35:32,282:INFO:SubProcess create_model() called ==================================
2024-06-06 14:35:32,283:INFO:Initializing create_model()
2024-06-06 14:35:32,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 14:35:32,283:INFO:Checking exceptions
2024-06-06 14:35:32,284:INFO:Importing libraries
2024-06-06 14:35:32,287:INFO:Copying training dataset
2024-06-06 14:35:33,121:INFO:Defining folds
2024-06-06 14:35:33,122:INFO:Declaring metric variables
2024-06-06 14:35:33,130:INFO:Importing untrained model
2024-06-06 14:35:33,137:INFO:Extreme Gradient Boosting Imported successfully
2024-06-06 14:35:33,148:INFO:Starting cross validation
2024-06-06 14:35:33,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 14:37:17,022:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:37:17,056:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:39:01,109:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:39:03,051:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:39:03,392:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:40:30,396:INFO:Calculating mean and std
2024-06-06 14:40:30,397:INFO:Creating metrics dataframe
2024-06-06 14:40:30,403:INFO:Uploading results into container
2024-06-06 14:40:30,405:INFO:Uploading model into container now
2024-06-06 14:40:30,406:INFO:_master_model_container: 13
2024-06-06 14:40:30,406:INFO:_display_container: 2
2024-06-06 14:40:30,410:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-06-06 14:40:30,410:INFO:create_model() successfully completed......................................
2024-06-06 14:40:30,528:INFO:SubProcess create_model() end ==================================
2024-06-06 14:40:30,529:INFO:Creating metrics dataframe
2024-06-06 14:40:30,556:INFO:Initializing Light Gradient Boosting Machine
2024-06-06 14:40:30,556:INFO:Total runtime is 230.12653100490573 minutes
2024-06-06 14:40:30,561:INFO:SubProcess create_model() called ==================================
2024-06-06 14:40:30,562:INFO:Initializing create_model()
2024-06-06 14:40:30,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 14:40:30,563:INFO:Checking exceptions
2024-06-06 14:40:30,563:INFO:Importing libraries
2024-06-06 14:40:30,564:INFO:Copying training dataset
2024-06-06 14:40:30,933:INFO:Defining folds
2024-06-06 14:40:30,934:INFO:Declaring metric variables
2024-06-06 14:40:30,940:INFO:Importing untrained model
2024-06-06 14:40:30,946:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-06 14:40:30,957:INFO:Starting cross validation
2024-06-06 14:40:30,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 14:42:32,119:INFO:Calculating mean and std
2024-06-06 14:42:32,121:INFO:Creating metrics dataframe
2024-06-06 14:42:32,128:INFO:Uploading results into container
2024-06-06 14:42:32,129:INFO:Uploading model into container now
2024-06-06 14:42:32,130:INFO:_master_model_container: 14
2024-06-06 14:42:32,131:INFO:_display_container: 2
2024-06-06 14:42:32,133:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3511, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-06 14:42:32,134:INFO:create_model() successfully completed......................................
2024-06-06 14:42:32,255:INFO:SubProcess create_model() end ==================================
2024-06-06 14:42:32,256:INFO:Creating metrics dataframe
2024-06-06 14:42:32,278:INFO:Initializing Dummy Classifier
2024-06-06 14:42:32,278:INFO:Total runtime is 232.1552324930827 minutes
2024-06-06 14:42:32,283:INFO:SubProcess create_model() called ==================================
2024-06-06 14:42:32,284:INFO:Initializing create_model()
2024-06-06 14:42:32,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205083767D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 14:42:32,285:INFO:Checking exceptions
2024-06-06 14:42:32,285:INFO:Importing libraries
2024-06-06 14:42:32,285:INFO:Copying training dataset
2024-06-06 14:42:32,661:INFO:Defining folds
2024-06-06 14:42:32,661:INFO:Declaring metric variables
2024-06-06 14:42:32,667:INFO:Importing untrained model
2024-06-06 14:42:32,673:INFO:Dummy Classifier Imported successfully
2024-06-06 14:42:32,683:INFO:Starting cross validation
2024-06-06 14:42:32,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 14:42:34,695:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:34,746:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:34,777:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:34,799:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:36,583:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:36,712:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:36,719:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:37,887:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:37,960:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 14:42:38,105:INFO:Calculating mean and std
2024-06-06 14:42:38,107:INFO:Creating metrics dataframe
2024-06-06 14:42:38,111:INFO:Uploading results into container
2024-06-06 14:42:38,112:INFO:Uploading model into container now
2024-06-06 14:42:38,113:INFO:_master_model_container: 15
2024-06-06 14:42:38,114:INFO:_display_container: 2
2024-06-06 14:42:38,114:INFO:DummyClassifier(constant=None, random_state=3511, strategy='prior')
2024-06-06 14:42:38,115:INFO:create_model() successfully completed......................................
2024-06-06 14:42:38,237:INFO:SubProcess create_model() end ==================================
2024-06-06 14:42:38,237:INFO:Creating metrics dataframe
2024-06-06 14:42:38,275:INFO:Initializing create_model()
2024-06-06 14:42:38,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020507E36810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3511, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 14:42:38,276:INFO:Checking exceptions
2024-06-06 14:42:38,282:INFO:Importing libraries
2024-06-06 14:42:38,282:INFO:Copying training dataset
2024-06-06 14:42:38,675:INFO:Defining folds
2024-06-06 14:42:38,676:INFO:Declaring metric variables
2024-06-06 14:42:38,677:INFO:Importing untrained model
2024-06-06 14:42:38,677:INFO:Declaring custom model
2024-06-06 14:42:38,678:INFO:Random Forest Classifier Imported successfully
2024-06-06 14:42:38,680:INFO:Cross validation set to False
2024-06-06 14:42:38,680:INFO:Fitting Model
2024-06-06 14:43:31,553:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3511, verbose=0,
                       warm_start=False)
2024-06-06 14:43:31,553:INFO:create_model() successfully completed......................................
2024-06-06 14:43:31,728:INFO:_master_model_container: 15
2024-06-06 14:43:31,729:INFO:_display_container: 2
2024-06-06 14:43:31,730:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3511, verbose=0,
                       warm_start=False)
2024-06-06 14:43:31,730:INFO:compare_models() successfully completed......................................
2024-06-06 15:06:57,541:INFO:PyCaret ClassificationExperiment
2024-06-06 15:06:57,551:INFO:Logging name: clf-default-name
2024-06-06 15:06:57,552:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-06 15:06:57,552:INFO:version 3.3.2
2024-06-06 15:06:57,552:INFO:Initializing setup()
2024-06-06 15:06:57,552:INFO:self.USI: 0236
2024-06-06 15:06:57,553:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'fix_imbalance', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'is_multiclass', 'X_test'}
2024-06-06 15:06:57,553:INFO:Checking environment
2024-06-06 15:06:57,553:INFO:python_version: 3.11.5
2024-06-06 15:06:57,554:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 15:06:57,554:INFO:machine: AMD64
2024-06-06 15:06:57,554:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 15:06:57,554:INFO:Memory: svmem(total=21420621824, available=9010704384, percent=57.9, used=12409917440, free=9010704384)
2024-06-06 15:06:57,555:INFO:Physical Core: 4
2024-06-06 15:06:57,555:INFO:Logical Core: 4
2024-06-06 15:06:57,555:INFO:Checking libraries
2024-06-06 15:06:57,556:INFO:System:
2024-06-06 15:06:57,556:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 15:06:57,556:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 15:06:57,556:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 15:06:57,557:INFO:PyCaret required dependencies:
2024-06-06 15:06:57,557:INFO:                 pip: 23.2.1
2024-06-06 15:06:57,557:INFO:          setuptools: 68.0.0
2024-06-06 15:06:57,558:INFO:             pycaret: 3.3.2
2024-06-06 15:06:57,558:INFO:             IPython: 8.20.0
2024-06-06 15:06:57,558:INFO:          ipywidgets: 8.1.2
2024-06-06 15:06:57,558:INFO:                tqdm: 4.65.0
2024-06-06 15:06:57,559:INFO:               numpy: 1.26.4
2024-06-06 15:06:57,559:INFO:              pandas: 1.5.3
2024-06-06 15:06:57,559:INFO:              jinja2: 3.1.3
2024-06-06 15:06:57,559:INFO:               scipy: 1.11.4
2024-06-06 15:06:57,560:INFO:              joblib: 1.2.0
2024-06-06 15:06:57,560:INFO:             sklearn: 1.4.2
2024-06-06 15:06:57,562:INFO:                pyod: 2.0.0
2024-06-06 15:06:57,563:INFO:            imblearn: 0.12.3
2024-06-06 15:06:57,564:INFO:   category_encoders: 2.6.3
2024-06-06 15:06:57,564:INFO:            lightgbm: 4.3.0
2024-06-06 15:06:57,564:INFO:               numba: 0.59.1
2024-06-06 15:06:57,564:INFO:            requests: 2.31.0
2024-06-06 15:06:57,565:INFO:          matplotlib: 3.7.5
2024-06-06 15:06:57,566:INFO:          scikitplot: 0.3.7
2024-06-06 15:06:57,568:INFO:         yellowbrick: 1.5
2024-06-06 15:06:57,568:INFO:              plotly: 5.19.0
2024-06-06 15:06:57,568:INFO:    plotly-resampler: Not installed
2024-06-06 15:06:57,568:INFO:             kaleido: 0.2.1
2024-06-06 15:06:57,569:INFO:           schemdraw: 0.15
2024-06-06 15:06:57,569:INFO:         statsmodels: 0.14.0
2024-06-06 15:06:57,569:INFO:              sktime: 0.26.0
2024-06-06 15:06:57,569:INFO:               tbats: 1.1.3
2024-06-06 15:06:57,570:INFO:            pmdarima: 2.0.4
2024-06-06 15:06:57,570:INFO:              psutil: 5.9.0
2024-06-06 15:06:57,570:INFO:          markupsafe: 2.1.3
2024-06-06 15:06:57,570:INFO:             pickle5: Not installed
2024-06-06 15:06:57,571:INFO:         cloudpickle: 2.2.1
2024-06-06 15:06:57,571:INFO:         deprecation: 2.1.0
2024-06-06 15:06:57,571:INFO:              xxhash: 2.0.2
2024-06-06 15:06:57,572:INFO:           wurlitzer: Not installed
2024-06-06 15:06:57,572:INFO:PyCaret optional dependencies:
2024-06-06 15:06:57,572:INFO:                shap: Not installed
2024-06-06 15:06:57,572:INFO:           interpret: Not installed
2024-06-06 15:06:57,572:INFO:                umap: Not installed
2024-06-06 15:06:57,572:INFO:     ydata_profiling: Not installed
2024-06-06 15:06:57,573:INFO:  explainerdashboard: Not installed
2024-06-06 15:06:57,573:INFO:             autoviz: Not installed
2024-06-06 15:06:57,573:INFO:           fairlearn: Not installed
2024-06-06 15:06:57,574:INFO:          deepchecks: Not installed
2024-06-06 15:06:57,574:INFO:             xgboost: 2.0.3
2024-06-06 15:06:57,574:INFO:            catboost: Not installed
2024-06-06 15:06:57,575:INFO:              kmodes: Not installed
2024-06-06 15:06:57,575:INFO:             mlxtend: Not installed
2024-06-06 15:06:57,575:INFO:       statsforecast: Not installed
2024-06-06 15:06:57,576:INFO:        tune_sklearn: Not installed
2024-06-06 15:06:57,576:INFO:                 ray: Not installed
2024-06-06 15:06:57,576:INFO:            hyperopt: Not installed
2024-06-06 15:06:57,576:INFO:              optuna: Not installed
2024-06-06 15:06:57,576:INFO:               skopt: Not installed
2024-06-06 15:06:57,577:INFO:              mlflow: Not installed
2024-06-06 15:06:57,581:INFO:              gradio: Not installed
2024-06-06 15:06:57,582:INFO:             fastapi: Not installed
2024-06-06 15:06:57,582:INFO:             uvicorn: Not installed
2024-06-06 15:06:57,582:INFO:              m2cgen: Not installed
2024-06-06 15:06:57,582:INFO:           evidently: Not installed
2024-06-06 15:06:57,583:INFO:               fugue: Not installed
2024-06-06 15:06:57,583:INFO:           streamlit: Not installed
2024-06-06 15:06:57,584:INFO:             prophet: Not installed
2024-06-06 15:06:57,584:INFO:None
2024-06-06 15:06:57,584:INFO:Set up data.
2024-06-06 15:06:58,084:INFO:Set up folding strategy.
2024-06-06 15:06:58,084:INFO:Set up train/test split.
2024-06-06 15:06:58,878:INFO:Set up index.
2024-06-06 15:06:58,931:INFO:Assigning column types.
2024-06-06 15:06:59,273:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 15:06:59,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,368:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,425:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:06:59,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:06:59,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,580:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:06:59,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:06:59,589:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 15:06:59,681:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,731:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:06:59,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:06:59,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:06:59,877:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:06:59,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:06:59,883:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-06 15:07:00,017:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:07:00,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:07:00,166:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:07:00,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:07:00,174:INFO:Preparing preprocessing pipeline...
2024-06-06 15:07:00,231:INFO:Set up simple imputation.
2024-06-06 15:07:01,359:INFO:Finished creating preprocessing pipeline.
2024-06-06 15:07:01,365:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-06 15:07:01,366:INFO:Creating final display dataframe.
2024-06-06 15:07:03,805:INFO:Setup _display_container:                     Description             Value
0                    Session id              7793
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0236
2024-06-06 15:07:03,964:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:07:03,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:07:04,107:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:07:04,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:07:04,115:INFO:setup() successfully completed in 6.61s...............
2024-06-06 15:08:03,232:INFO:PyCaret ClassificationExperiment
2024-06-06 15:08:03,430:INFO:Logging name: clf-default-name
2024-06-06 15:08:03,431:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-06 15:08:03,431:INFO:version 3.3.2
2024-06-06 15:08:03,431:INFO:Initializing setup()
2024-06-06 15:08:03,431:INFO:self.USI: 814a
2024-06-06 15:08:03,432:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'fix_imbalance', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'is_multiclass', 'X_test'}
2024-06-06 15:08:03,432:INFO:Checking environment
2024-06-06 15:08:03,432:INFO:python_version: 3.11.5
2024-06-06 15:08:03,432:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 15:08:03,433:INFO:machine: AMD64
2024-06-06 15:08:03,433:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 15:08:03,433:INFO:Memory: svmem(total=21420621824, available=8856911872, percent=58.7, used=12563709952, free=8856911872)
2024-06-06 15:08:03,433:INFO:Physical Core: 4
2024-06-06 15:08:03,433:INFO:Logical Core: 4
2024-06-06 15:08:03,434:INFO:Checking libraries
2024-06-06 15:08:03,434:INFO:System:
2024-06-06 15:08:03,434:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 15:08:03,434:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 15:08:03,434:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 15:08:03,435:INFO:PyCaret required dependencies:
2024-06-06 15:08:03,435:INFO:                 pip: 23.2.1
2024-06-06 15:08:03,435:INFO:          setuptools: 68.0.0
2024-06-06 15:08:03,435:INFO:             pycaret: 3.3.2
2024-06-06 15:08:03,435:INFO:             IPython: 8.20.0
2024-06-06 15:08:03,436:INFO:          ipywidgets: 8.1.2
2024-06-06 15:08:03,436:INFO:                tqdm: 4.65.0
2024-06-06 15:08:03,436:INFO:               numpy: 1.26.4
2024-06-06 15:08:03,436:INFO:              pandas: 1.5.3
2024-06-06 15:08:03,436:INFO:              jinja2: 3.1.3
2024-06-06 15:08:03,437:INFO:               scipy: 1.11.4
2024-06-06 15:08:03,437:INFO:              joblib: 1.2.0
2024-06-06 15:08:03,437:INFO:             sklearn: 1.4.2
2024-06-06 15:08:03,437:INFO:                pyod: 2.0.0
2024-06-06 15:08:03,437:INFO:            imblearn: 0.12.3
2024-06-06 15:08:03,437:INFO:   category_encoders: 2.6.3
2024-06-06 15:08:03,438:INFO:            lightgbm: 4.3.0
2024-06-06 15:08:03,438:INFO:               numba: 0.59.1
2024-06-06 15:08:03,438:INFO:            requests: 2.31.0
2024-06-06 15:08:03,439:INFO:          matplotlib: 3.7.5
2024-06-06 15:08:03,439:INFO:          scikitplot: 0.3.7
2024-06-06 15:08:03,439:INFO:         yellowbrick: 1.5
2024-06-06 15:08:03,439:INFO:              plotly: 5.19.0
2024-06-06 15:08:03,439:INFO:    plotly-resampler: Not installed
2024-06-06 15:08:03,440:INFO:             kaleido: 0.2.1
2024-06-06 15:08:03,443:INFO:           schemdraw: 0.15
2024-06-06 15:08:03,443:INFO:         statsmodels: 0.14.0
2024-06-06 15:08:03,443:INFO:              sktime: 0.26.0
2024-06-06 15:08:03,443:INFO:               tbats: 1.1.3
2024-06-06 15:08:03,444:INFO:            pmdarima: 2.0.4
2024-06-06 15:08:03,444:INFO:              psutil: 5.9.0
2024-06-06 15:08:03,444:INFO:          markupsafe: 2.1.3
2024-06-06 15:08:03,444:INFO:             pickle5: Not installed
2024-06-06 15:08:03,444:INFO:         cloudpickle: 2.2.1
2024-06-06 15:08:03,445:INFO:         deprecation: 2.1.0
2024-06-06 15:08:03,445:INFO:              xxhash: 2.0.2
2024-06-06 15:08:03,445:INFO:           wurlitzer: Not installed
2024-06-06 15:08:03,445:INFO:PyCaret optional dependencies:
2024-06-06 15:08:03,445:INFO:                shap: Not installed
2024-06-06 15:08:03,446:INFO:           interpret: Not installed
2024-06-06 15:08:03,446:INFO:                umap: Not installed
2024-06-06 15:08:03,446:INFO:     ydata_profiling: Not installed
2024-06-06 15:08:03,446:INFO:  explainerdashboard: Not installed
2024-06-06 15:08:03,446:INFO:             autoviz: Not installed
2024-06-06 15:08:03,447:INFO:           fairlearn: Not installed
2024-06-06 15:08:03,447:INFO:          deepchecks: Not installed
2024-06-06 15:08:03,447:INFO:             xgboost: 2.0.3
2024-06-06 15:08:03,447:INFO:            catboost: Not installed
2024-06-06 15:08:03,447:INFO:              kmodes: Not installed
2024-06-06 15:08:03,448:INFO:             mlxtend: Not installed
2024-06-06 15:08:03,448:INFO:       statsforecast: Not installed
2024-06-06 15:08:03,448:INFO:        tune_sklearn: Not installed
2024-06-06 15:08:03,448:INFO:                 ray: Not installed
2024-06-06 15:08:03,448:INFO:            hyperopt: Not installed
2024-06-06 15:08:03,448:INFO:              optuna: Not installed
2024-06-06 15:08:03,449:INFO:               skopt: Not installed
2024-06-06 15:08:03,449:INFO:              mlflow: Not installed
2024-06-06 15:08:03,449:INFO:              gradio: Not installed
2024-06-06 15:08:03,449:INFO:             fastapi: Not installed
2024-06-06 15:08:03,449:INFO:             uvicorn: Not installed
2024-06-06 15:08:03,450:INFO:              m2cgen: Not installed
2024-06-06 15:08:03,450:INFO:           evidently: Not installed
2024-06-06 15:08:03,450:INFO:               fugue: Not installed
2024-06-06 15:08:03,450:INFO:           streamlit: Not installed
2024-06-06 15:08:03,450:INFO:             prophet: Not installed
2024-06-06 15:08:03,450:INFO:None
2024-06-06 15:08:03,451:INFO:Set up data.
2024-06-06 15:08:03,882:INFO:Set up folding strategy.
2024-06-06 15:08:03,882:INFO:Set up train/test split.
2024-06-06 15:08:04,822:INFO:Set up index.
2024-06-06 15:08:04,870:INFO:Assigning column types.
2024-06-06 15:08:05,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 15:08:05,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,323:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:05,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:05,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,416:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,470:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:05,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:05,476:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 15:08:05,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,613:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:05,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:05,707:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 15:08:05,758:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:05,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:05,765:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-06 15:08:05,896:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:05,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:06,031:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:06,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:06,039:INFO:Preparing preprocessing pipeline...
2024-06-06 15:08:06,095:INFO:Set up simple imputation.
2024-06-06 15:08:07,135:INFO:Finished creating preprocessing pipeline.
2024-06-06 15:08:07,142:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-06 15:08:07,143:INFO:Creating final display dataframe.
2024-06-06 15:08:09,267:INFO:Setup _display_container:                     Description             Value
0                    Session id              8671
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              814a
2024-06-06 15:08:09,431:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:09,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:09,574:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 15:08:09,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 15:08:09,584:INFO:setup() successfully completed in 6.41s...............
2024-06-06 15:08:26,817:INFO:Initializing compare_models()
2024-06-06 15:08:26,820:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, include=['rf', 'dt', 'knn', 'xgboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, 'include': ['rf', 'dt', 'knn', 'xgboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-06 15:08:26,829:INFO:Checking exceptions
2024-06-06 15:08:27,233:INFO:Preparing display monitor
2024-06-06 15:08:27,282:INFO:Initializing Random Forest Classifier
2024-06-06 15:08:27,288:INFO:Total runtime is 9.999275207519531e-05 minutes
2024-06-06 15:08:27,298:INFO:SubProcess create_model() called ==================================
2024-06-06 15:08:27,303:INFO:Initializing create_model()
2024-06-06 15:08:27,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051CB3F2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 15:08:27,304:INFO:Checking exceptions
2024-06-06 15:08:27,305:INFO:Importing libraries
2024-06-06 15:08:27,305:INFO:Copying training dataset
2024-06-06 15:08:27,885:INFO:Defining folds
2024-06-06 15:08:27,886:INFO:Declaring metric variables
2024-06-06 15:08:27,890:INFO:Importing untrained model
2024-06-06 15:08:27,898:INFO:Random Forest Classifier Imported successfully
2024-06-06 15:08:27,906:INFO:Starting cross validation
2024-06-06 15:08:27,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 15:18:21,655:INFO:Calculating mean and std
2024-06-06 15:18:21,838:INFO:Creating metrics dataframe
2024-06-06 15:18:22,044:INFO:Uploading results into container
2024-06-06 15:18:22,066:INFO:Uploading model into container now
2024-06-06 15:18:22,093:INFO:_master_model_container: 1
2024-06-06 15:18:22,093:INFO:_display_container: 2
2024-06-06 15:18:22,108:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8671, verbose=0,
                       warm_start=False)
2024-06-06 15:18:22,109:INFO:create_model() successfully completed......................................
2024-06-06 15:18:25,123:INFO:SubProcess create_model() end ==================================
2024-06-06 15:18:25,123:INFO:Creating metrics dataframe
2024-06-06 15:18:25,157:INFO:Initializing Decision Tree Classifier
2024-06-06 15:18:25,158:INFO:Total runtime is 9.964612805843354 minutes
2024-06-06 15:18:25,164:INFO:SubProcess create_model() called ==================================
2024-06-06 15:18:25,166:INFO:Initializing create_model()
2024-06-06 15:18:25,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051CB3F2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 15:18:25,166:INFO:Checking exceptions
2024-06-06 15:18:25,168:INFO:Importing libraries
2024-06-06 15:18:25,171:INFO:Copying training dataset
2024-06-06 15:18:26,531:INFO:Defining folds
2024-06-06 15:18:26,531:INFO:Declaring metric variables
2024-06-06 15:18:26,541:INFO:Importing untrained model
2024-06-06 15:18:26,547:INFO:Decision Tree Classifier Imported successfully
2024-06-06 15:18:26,558:INFO:Starting cross validation
2024-06-06 15:18:26,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 15:19:06,774:INFO:Calculating mean and std
2024-06-06 15:19:06,777:INFO:Creating metrics dataframe
2024-06-06 15:19:06,782:INFO:Uploading results into container
2024-06-06 15:19:06,783:INFO:Uploading model into container now
2024-06-06 15:19:06,785:INFO:_master_model_container: 2
2024-06-06 15:19:06,785:INFO:_display_container: 2
2024-06-06 15:19:06,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8671, splitter='best')
2024-06-06 15:19:06,788:INFO:create_model() successfully completed......................................
2024-06-06 15:19:06,941:INFO:SubProcess create_model() end ==================================
2024-06-06 15:19:06,941:INFO:Creating metrics dataframe
2024-06-06 15:19:06,960:INFO:Initializing K Neighbors Classifier
2024-06-06 15:19:06,961:INFO:Total runtime is 10.661303774515789 minutes
2024-06-06 15:19:06,966:INFO:SubProcess create_model() called ==================================
2024-06-06 15:19:06,967:INFO:Initializing create_model()
2024-06-06 15:19:06,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051CB3F2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 15:19:06,968:INFO:Checking exceptions
2024-06-06 15:19:06,968:INFO:Importing libraries
2024-06-06 15:19:06,969:INFO:Copying training dataset
2024-06-06 15:19:07,489:INFO:Defining folds
2024-06-06 15:19:07,489:INFO:Declaring metric variables
2024-06-06 15:19:07,498:INFO:Importing untrained model
2024-06-06 15:19:07,503:INFO:K Neighbors Classifier Imported successfully
2024-06-06 15:19:07,515:INFO:Starting cross validation
2024-06-06 15:19:07,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 15:27:49,897:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:36:27,286:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:36:27,562:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:36:28,093:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:36:28,476:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:43:32,104:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:43:32,272:INFO:Calculating mean and std
2024-06-06 15:43:32,277:INFO:Creating metrics dataframe
2024-06-06 15:43:32,285:INFO:Uploading results into container
2024-06-06 15:43:32,287:INFO:Uploading model into container now
2024-06-06 15:43:32,287:INFO:_master_model_container: 3
2024-06-06 15:43:32,288:INFO:_display_container: 2
2024-06-06 15:43:32,288:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-06 15:43:32,288:INFO:create_model() successfully completed......................................
2024-06-06 15:43:32,459:INFO:SubProcess create_model() end ==================================
2024-06-06 15:43:32,459:INFO:Creating metrics dataframe
2024-06-06 15:43:32,480:INFO:Initializing Extreme Gradient Boosting
2024-06-06 15:43:32,481:INFO:Total runtime is 35.086655322710676 minutes
2024-06-06 15:43:32,486:INFO:SubProcess create_model() called ==================================
2024-06-06 15:43:32,487:INFO:Initializing create_model()
2024-06-06 15:43:32,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051CB3F2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 15:43:32,488:INFO:Checking exceptions
2024-06-06 15:43:32,488:INFO:Importing libraries
2024-06-06 15:43:32,488:INFO:Copying training dataset
2024-06-06 15:43:33,079:INFO:Defining folds
2024-06-06 15:43:33,079:INFO:Declaring metric variables
2024-06-06 15:43:33,086:INFO:Importing untrained model
2024-06-06 15:43:33,097:INFO:Extreme Gradient Boosting Imported successfully
2024-06-06 15:43:33,108:INFO:Starting cross validation
2024-06-06 15:43:33,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 15:45:31,562:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:45:32,509:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:45:41,586:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:45:43,108:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:47:41,218:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:47:41,336:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:47:48,218:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:47:50,483:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:49:16,555:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:49:17,055:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-06 15:49:17,221:INFO:Calculating mean and std
2024-06-06 15:49:17,222:INFO:Creating metrics dataframe
2024-06-06 15:49:17,235:INFO:Uploading results into container
2024-06-06 15:49:17,236:INFO:Uploading model into container now
2024-06-06 15:49:17,237:INFO:_master_model_container: 4
2024-06-06 15:49:17,237:INFO:_display_container: 2
2024-06-06 15:49:17,239:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-06-06 15:49:17,239:INFO:create_model() successfully completed......................................
2024-06-06 15:49:17,405:INFO:SubProcess create_model() end ==================================
2024-06-06 15:49:17,406:INFO:Creating metrics dataframe
2024-06-06 15:49:17,441:INFO:Initializing create_model()
2024-06-06 15:49:17,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002051CA027D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8671, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 15:49:17,442:INFO:Checking exceptions
2024-06-06 15:49:17,449:INFO:Importing libraries
2024-06-06 15:49:17,451:INFO:Copying training dataset
2024-06-06 15:49:18,121:INFO:Defining folds
2024-06-06 15:49:18,121:INFO:Declaring metric variables
2024-06-06 15:49:18,121:INFO:Importing untrained model
2024-06-06 15:49:18,122:INFO:Declaring custom model
2024-06-06 15:49:18,123:INFO:Random Forest Classifier Imported successfully
2024-06-06 15:49:18,125:INFO:Cross validation set to False
2024-06-06 15:49:18,125:INFO:Fitting Model
2024-06-06 15:50:17,097:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8671, verbose=0,
                       warm_start=False)
2024-06-06 15:50:17,098:INFO:create_model() successfully completed......................................
2024-06-06 15:50:17,303:INFO:_master_model_container: 4
2024-06-06 15:50:17,305:INFO:_display_container: 2
2024-06-06 15:50:17,307:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8671, verbose=0,
                       warm_start=False)
2024-06-06 15:50:17,307:INFO:compare_models() successfully completed......................................
2024-06-06 18:34:18,888:INFO:PyCaret ClassificationExperiment
2024-06-06 18:34:18,895:INFO:Logging name: clf-default-name
2024-06-06 18:34:18,895:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-06 18:34:18,896:INFO:version 3.3.2
2024-06-06 18:34:18,896:INFO:Initializing setup()
2024-06-06 18:34:18,896:INFO:self.USI: e051
2024-06-06 18:34:18,897:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'fix_imbalance', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'is_multiclass', 'X_test'}
2024-06-06 18:34:18,897:INFO:Checking environment
2024-06-06 18:34:18,897:INFO:python_version: 3.11.5
2024-06-06 18:34:18,898:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 18:34:18,898:INFO:machine: AMD64
2024-06-06 18:34:18,898:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 18:34:18,899:INFO:Memory: svmem(total=21420621824, available=8865480704, percent=58.6, used=12555141120, free=8865480704)
2024-06-06 18:34:18,899:INFO:Physical Core: 4
2024-06-06 18:34:18,900:INFO:Logical Core: 4
2024-06-06 18:34:18,900:INFO:Checking libraries
2024-06-06 18:34:18,900:INFO:System:
2024-06-06 18:34:18,901:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 18:34:18,901:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 18:34:18,901:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 18:34:18,902:INFO:PyCaret required dependencies:
2024-06-06 18:34:18,902:INFO:                 pip: 23.2.1
2024-06-06 18:34:18,902:INFO:          setuptools: 68.0.0
2024-06-06 18:34:18,902:INFO:             pycaret: 3.3.2
2024-06-06 18:34:18,903:INFO:             IPython: 8.20.0
2024-06-06 18:34:18,903:INFO:          ipywidgets: 8.1.2
2024-06-06 18:34:18,903:INFO:                tqdm: 4.65.0
2024-06-06 18:34:18,904:INFO:               numpy: 1.26.4
2024-06-06 18:34:18,904:INFO:              pandas: 1.5.3
2024-06-06 18:34:18,904:INFO:              jinja2: 3.1.3
2024-06-06 18:34:18,904:INFO:               scipy: 1.11.4
2024-06-06 18:34:18,905:INFO:              joblib: 1.2.0
2024-06-06 18:34:18,905:INFO:             sklearn: 1.4.2
2024-06-06 18:34:18,905:INFO:                pyod: 2.0.0
2024-06-06 18:34:18,906:INFO:            imblearn: 0.12.3
2024-06-06 18:34:18,906:INFO:   category_encoders: 2.6.3
2024-06-06 18:34:18,906:INFO:            lightgbm: 4.3.0
2024-06-06 18:34:18,907:INFO:               numba: 0.59.1
2024-06-06 18:34:18,908:INFO:            requests: 2.31.0
2024-06-06 18:34:18,910:INFO:          matplotlib: 3.7.5
2024-06-06 18:34:18,911:INFO:          scikitplot: 0.3.7
2024-06-06 18:34:18,912:INFO:         yellowbrick: 1.5
2024-06-06 18:34:18,912:INFO:              plotly: 5.19.0
2024-06-06 18:34:18,912:INFO:    plotly-resampler: Not installed
2024-06-06 18:34:18,912:INFO:             kaleido: 0.2.1
2024-06-06 18:34:18,913:INFO:           schemdraw: 0.15
2024-06-06 18:34:18,915:INFO:         statsmodels: 0.14.0
2024-06-06 18:34:18,915:INFO:              sktime: 0.26.0
2024-06-06 18:34:18,916:INFO:               tbats: 1.1.3
2024-06-06 18:34:18,916:INFO:            pmdarima: 2.0.4
2024-06-06 18:34:18,916:INFO:              psutil: 5.9.0
2024-06-06 18:34:18,916:INFO:          markupsafe: 2.1.3
2024-06-06 18:34:18,917:INFO:             pickle5: Not installed
2024-06-06 18:34:18,917:INFO:         cloudpickle: 2.2.1
2024-06-06 18:34:18,918:INFO:         deprecation: 2.1.0
2024-06-06 18:34:18,918:INFO:              xxhash: 2.0.2
2024-06-06 18:34:18,918:INFO:           wurlitzer: Not installed
2024-06-06 18:34:18,918:INFO:PyCaret optional dependencies:
2024-06-06 18:34:18,919:INFO:                shap: Not installed
2024-06-06 18:34:18,919:INFO:           interpret: Not installed
2024-06-06 18:34:18,919:INFO:                umap: Not installed
2024-06-06 18:34:18,919:INFO:     ydata_profiling: Not installed
2024-06-06 18:34:18,920:INFO:  explainerdashboard: Not installed
2024-06-06 18:34:18,920:INFO:             autoviz: Not installed
2024-06-06 18:34:18,920:INFO:           fairlearn: Not installed
2024-06-06 18:34:18,920:INFO:          deepchecks: Not installed
2024-06-06 18:34:18,921:INFO:             xgboost: 2.0.3
2024-06-06 18:34:18,921:INFO:            catboost: Not installed
2024-06-06 18:34:18,921:INFO:              kmodes: Not installed
2024-06-06 18:34:18,922:INFO:             mlxtend: Not installed
2024-06-06 18:34:18,922:INFO:       statsforecast: Not installed
2024-06-06 18:34:18,922:INFO:        tune_sklearn: Not installed
2024-06-06 18:34:18,922:INFO:                 ray: Not installed
2024-06-06 18:34:18,923:INFO:            hyperopt: Not installed
2024-06-06 18:34:18,924:INFO:              optuna: Not installed
2024-06-06 18:34:18,924:INFO:               skopt: Not installed
2024-06-06 18:34:18,924:INFO:              mlflow: Not installed
2024-06-06 18:34:18,926:INFO:              gradio: Not installed
2024-06-06 18:34:18,926:INFO:             fastapi: Not installed
2024-06-06 18:34:18,927:INFO:             uvicorn: Not installed
2024-06-06 18:34:18,928:INFO:              m2cgen: Not installed
2024-06-06 18:34:18,928:INFO:           evidently: Not installed
2024-06-06 18:34:18,928:INFO:               fugue: Not installed
2024-06-06 18:34:18,928:INFO:           streamlit: Not installed
2024-06-06 18:34:18,929:INFO:             prophet: Not installed
2024-06-06 18:34:18,929:INFO:None
2024-06-06 18:34:18,930:INFO:Set up data.
2024-06-06 18:34:19,477:INFO:Set up folding strategy.
2024-06-06 18:34:19,478:INFO:Set up train/test split.
2024-06-06 18:34:20,299:INFO:Set up index.
2024-06-06 18:34:20,350:INFO:Assigning column types.
2024-06-06 18:34:20,669:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 18:34:20,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:34:20,754:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 18:34:20,805:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:20,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:20,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:34:20,891:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 18:34:20,941:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:20,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:20,948:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 18:34:21,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 18:34:21,074:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:21,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:21,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-06 18:34:21,212:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:21,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:21,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-06 18:34:21,343:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:21,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:21,481:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:21,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:21,489:INFO:Preparing preprocessing pipeline...
2024-06-06 18:34:21,543:INFO:Set up simple imputation.
2024-06-06 18:34:22,717:INFO:Finished creating preprocessing pipeline.
2024-06-06 18:34:22,724:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-06 18:34:22,724:INFO:Creating final display dataframe.
2024-06-06 18:34:24,885:INFO:Setup _display_container:                     Description             Value
0                    Session id              7797
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e051
2024-06-06 18:34:25,053:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:25,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:25,222:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:34:25,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:34:25,229:INFO:setup() successfully completed in 6.37s...............
2024-06-06 18:35:04,172:INFO:Initializing compare_models()
2024-06-06 18:35:04,174:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020510E94D90>, include=['lightgbm', 'xgboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020510E94D90>, 'include': ['lightgbm', 'xgboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-06 18:35:04,176:INFO:Checking exceptions
2024-06-06 18:35:04,515:INFO:Preparing display monitor
2024-06-06 18:35:04,578:INFO:Initializing Light Gradient Boosting Machine
2024-06-06 18:35:04,648:INFO:Total runtime is 0.0011667172114054362 minutes
2024-06-06 18:35:04,682:INFO:SubProcess create_model() called ==================================
2024-06-06 18:35:04,689:INFO:Initializing create_model()
2024-06-06 18:35:04,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020510E94D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020508365ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 18:35:04,691:INFO:Checking exceptions
2024-06-06 18:35:04,691:INFO:Importing libraries
2024-06-06 18:35:04,691:INFO:Copying training dataset
2024-06-06 18:35:05,250:INFO:Defining folds
2024-06-06 18:35:05,250:INFO:Declaring metric variables
2024-06-06 18:35:05,256:INFO:Importing untrained model
2024-06-06 18:35:05,262:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-06 18:35:05,272:INFO:Starting cross validation
2024-06-06 18:35:05,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 18:38:27,069:INFO:PyCaret RegressionExperiment
2024-06-06 18:38:27,183:INFO:Logging name: reg-default-name
2024-06-06 18:38:27,183:INFO:ML Usecase: MLUsecase.REGRESSION
2024-06-06 18:38:27,184:INFO:version 3.3.2
2024-06-06 18:38:27,184:INFO:Initializing setup()
2024-06-06 18:38:27,184:INFO:self.USI: 99bb
2024-06-06 18:38:27,184:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_groups_param', 'gpu_param', 'X', 'data', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', 'seed', 'exp_id', 'y_train', 'html_param', 'y', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'transform_target_param', 'logging_param', 'X_train', '_available_plots', 'target_param', 'memory', 'X_test'}
2024-06-06 18:38:27,185:INFO:Checking environment
2024-06-06 18:38:27,185:INFO:python_version: 3.11.5
2024-06-06 18:38:27,185:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-06 18:38:27,185:INFO:machine: AMD64
2024-06-06 18:38:27,186:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-06 18:38:27,186:INFO:Memory: svmem(total=21420621824, available=8431779840, percent=60.6, used=12988841984, free=8431779840)
2024-06-06 18:38:27,186:INFO:Physical Core: 4
2024-06-06 18:38:27,186:INFO:Logical Core: 4
2024-06-06 18:38:27,187:INFO:Checking libraries
2024-06-06 18:38:27,187:INFO:System:
2024-06-06 18:38:27,187:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-06 18:38:27,187:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-06 18:38:27,187:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-06 18:38:27,188:INFO:PyCaret required dependencies:
2024-06-06 18:38:27,188:INFO:                 pip: 23.2.1
2024-06-06 18:38:27,188:INFO:          setuptools: 68.0.0
2024-06-06 18:38:27,188:INFO:             pycaret: 3.3.2
2024-06-06 18:38:27,188:INFO:             IPython: 8.20.0
2024-06-06 18:38:27,189:INFO:          ipywidgets: 8.1.2
2024-06-06 18:38:27,189:INFO:                tqdm: 4.65.0
2024-06-06 18:38:27,189:INFO:               numpy: 1.26.4
2024-06-06 18:38:27,190:INFO:              pandas: 1.5.3
2024-06-06 18:38:27,190:INFO:              jinja2: 3.1.3
2024-06-06 18:38:27,190:INFO:               scipy: 1.11.4
2024-06-06 18:38:27,190:INFO:              joblib: 1.2.0
2024-06-06 18:38:27,190:INFO:             sklearn: 1.4.2
2024-06-06 18:38:27,191:INFO:                pyod: 2.0.0
2024-06-06 18:38:27,191:INFO:            imblearn: 0.12.3
2024-06-06 18:38:27,191:INFO:   category_encoders: 2.6.3
2024-06-06 18:38:27,192:INFO:            lightgbm: 4.3.0
2024-06-06 18:38:27,193:INFO:               numba: 0.59.1
2024-06-06 18:38:27,193:INFO:            requests: 2.31.0
2024-06-06 18:38:27,193:INFO:          matplotlib: 3.7.5
2024-06-06 18:38:27,194:INFO:          scikitplot: 0.3.7
2024-06-06 18:38:27,194:INFO:         yellowbrick: 1.5
2024-06-06 18:38:27,194:INFO:              plotly: 5.19.0
2024-06-06 18:38:27,195:INFO:    plotly-resampler: Not installed
2024-06-06 18:38:27,195:INFO:             kaleido: 0.2.1
2024-06-06 18:38:27,195:INFO:           schemdraw: 0.15
2024-06-06 18:38:27,196:INFO:         statsmodels: 0.14.0
2024-06-06 18:38:27,197:INFO:              sktime: 0.26.0
2024-06-06 18:38:27,197:INFO:               tbats: 1.1.3
2024-06-06 18:38:27,197:INFO:            pmdarima: 2.0.4
2024-06-06 18:38:27,197:INFO:              psutil: 5.9.0
2024-06-06 18:38:27,198:INFO:          markupsafe: 2.1.3
2024-06-06 18:38:27,198:INFO:             pickle5: Not installed
2024-06-06 18:38:27,198:INFO:         cloudpickle: 2.2.1
2024-06-06 18:38:27,198:INFO:         deprecation: 2.1.0
2024-06-06 18:38:27,198:INFO:              xxhash: 2.0.2
2024-06-06 18:38:27,199:INFO:           wurlitzer: Not installed
2024-06-06 18:38:27,199:INFO:PyCaret optional dependencies:
2024-06-06 18:38:27,199:INFO:                shap: Not installed
2024-06-06 18:38:27,199:INFO:           interpret: Not installed
2024-06-06 18:38:27,199:INFO:                umap: Not installed
2024-06-06 18:38:27,200:INFO:     ydata_profiling: Not installed
2024-06-06 18:38:27,200:INFO:  explainerdashboard: Not installed
2024-06-06 18:38:27,200:INFO:             autoviz: Not installed
2024-06-06 18:38:27,200:INFO:           fairlearn: Not installed
2024-06-06 18:38:27,200:INFO:          deepchecks: Not installed
2024-06-06 18:38:27,201:INFO:             xgboost: 2.0.3
2024-06-06 18:38:27,201:INFO:            catboost: Not installed
2024-06-06 18:38:27,201:INFO:              kmodes: Not installed
2024-06-06 18:38:27,201:INFO:             mlxtend: Not installed
2024-06-06 18:38:27,201:INFO:       statsforecast: Not installed
2024-06-06 18:38:27,202:INFO:        tune_sklearn: Not installed
2024-06-06 18:38:27,202:INFO:                 ray: Not installed
2024-06-06 18:38:27,202:INFO:            hyperopt: Not installed
2024-06-06 18:38:27,202:INFO:              optuna: Not installed
2024-06-06 18:38:27,202:INFO:               skopt: Not installed
2024-06-06 18:38:27,203:INFO:              mlflow: Not installed
2024-06-06 18:38:27,203:INFO:              gradio: Not installed
2024-06-06 18:38:27,203:INFO:             fastapi: Not installed
2024-06-06 18:38:27,203:INFO:             uvicorn: Not installed
2024-06-06 18:38:27,203:INFO:              m2cgen: Not installed
2024-06-06 18:38:27,204:INFO:           evidently: Not installed
2024-06-06 18:38:27,204:INFO:               fugue: Not installed
2024-06-06 18:38:27,204:INFO:           streamlit: Not installed
2024-06-06 18:38:27,204:INFO:             prophet: Not installed
2024-06-06 18:38:27,205:INFO:None
2024-06-06 18:38:27,205:INFO:Set up data.
2024-06-06 18:38:27,621:INFO:Set up folding strategy.
2024-06-06 18:38:27,621:INFO:Set up train/test split.
2024-06-06 18:38:28,121:INFO:Set up index.
2024-06-06 18:38:28,171:INFO:Assigning column types.
2024-06-06 18:38:28,591:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-06 18:38:28,592:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 18:38:28,604:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 18:38:28,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,264:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:29,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:29,272:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,889:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:29,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:29,894:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-06-06 18:38:29,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 18:38:29,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:30,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:30,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:30,465:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:30,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:30,479:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-06 18:38:30,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:30,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:31,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:31,071:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:31,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:31,078:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-06-06 18:38:31,094:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:31,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:31,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:31,819:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:31,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:31,845:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-06 18:38:32,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:32,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:32,429:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:32,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:32,436:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-06-06 18:38:32,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:32,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:33,000:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:33,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:33,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:33,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-06 18:38:33,638:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:33,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:33,644:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-06 18:38:34,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:34,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:34,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:34,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-06 18:38:34,786:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:34,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:34,791:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-06-06 18:38:35,365:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:35,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:35,916:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:35,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:35,925:INFO:Preparing preprocessing pipeline...
2024-06-06 18:38:35,925:INFO:Set up simple imputation.
2024-06-06 18:38:36,928:INFO:Finished creating preprocessing pipeline.
2024-06-06 18:38:36,934:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-06 18:38:36,934:INFO:Creating final display dataframe.
2024-06-06 18:38:38,780:INFO:Setup _display_container:                     Description             Value
0                    Session id              6234
1                        Target            STATUS
2                   Target type        Regression
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              99bb
2024-06-06 18:38:39,394:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:39,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:39,941:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-06 18:38:39,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-06 18:38:39,946:INFO:setup() successfully completed in 12.89s...............
2024-06-06 18:38:44,778:INFO:Initializing compare_models()
2024-06-06 18:38:44,779:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FF28BD0>, include=['lightgbm', 'xgboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002053FF28BD0>, 'include': ['lightgbm', 'xgboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-06-06 18:38:44,780:INFO:Checking exceptions
2024-06-06 18:38:45,010:INFO:Preparing display monitor
2024-06-06 18:38:45,048:INFO:Initializing Light Gradient Boosting Machine
2024-06-06 18:38:45,048:INFO:Total runtime is 0.0 minutes
2024-06-06 18:38:45,058:INFO:SubProcess create_model() called ==================================
2024-06-06 18:38:45,058:INFO:Initializing create_model()
2024-06-06 18:38:45,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FF28BD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020537273410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 18:38:45,061:INFO:Checking exceptions
2024-06-06 18:38:45,062:INFO:Importing libraries
2024-06-06 18:38:45,062:INFO:Copying training dataset
2024-06-06 18:38:45,560:INFO:Defining folds
2024-06-06 18:38:45,561:INFO:Declaring metric variables
2024-06-06 18:38:45,565:INFO:Importing untrained model
2024-06-06 18:38:45,570:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-06 18:38:45,580:INFO:Starting cross validation
2024-06-06 18:38:45,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 18:39:17,592:INFO:Calculating mean and std
2024-06-06 18:39:17,594:INFO:Creating metrics dataframe
2024-06-06 18:39:17,621:INFO:Uploading results into container
2024-06-06 18:39:17,622:INFO:Uploading model into container now
2024-06-06 18:39:17,623:INFO:_master_model_container: 1
2024-06-06 18:39:17,623:INFO:_display_container: 2
2024-06-06 18:39:17,624:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6234, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-06-06 18:39:17,625:INFO:create_model() successfully completed......................................
2024-06-06 18:39:18,040:INFO:SubProcess create_model() end ==================================
2024-06-06 18:39:18,042:INFO:Creating metrics dataframe
2024-06-06 18:39:18,061:INFO:Initializing Extreme Gradient Boosting
2024-06-06 18:39:18,064:INFO:Total runtime is 0.550266170501709 minutes
2024-06-06 18:39:18,070:INFO:SubProcess create_model() called ==================================
2024-06-06 18:39:18,075:INFO:Initializing create_model()
2024-06-06 18:39:18,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FF28BD0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020537273410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 18:39:18,076:INFO:Checking exceptions
2024-06-06 18:39:18,076:INFO:Importing libraries
2024-06-06 18:39:18,076:INFO:Copying training dataset
2024-06-06 18:39:18,912:INFO:Defining folds
2024-06-06 18:39:18,912:INFO:Declaring metric variables
2024-06-06 18:39:18,925:INFO:Importing untrained model
2024-06-06 18:39:18,932:INFO:Extreme Gradient Boosting Imported successfully
2024-06-06 18:39:18,945:INFO:Starting cross validation
2024-06-06 18:39:18,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-06 18:40:04,481:INFO:Calculating mean and std
2024-06-06 18:40:04,483:INFO:Creating metrics dataframe
2024-06-06 18:40:04,492:INFO:Uploading results into container
2024-06-06 18:40:04,493:INFO:Uploading model into container now
2024-06-06 18:40:04,494:INFO:_master_model_container: 2
2024-06-06 18:40:04,494:INFO:_display_container: 2
2024-06-06 18:40:04,495:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-06-06 18:40:04,495:INFO:create_model() successfully completed......................................
2024-06-06 18:40:04,844:INFO:SubProcess create_model() end ==================================
2024-06-06 18:40:04,844:INFO:Creating metrics dataframe
2024-06-06 18:40:04,886:INFO:Initializing create_model()
2024-06-06 18:40:04,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FF28BD0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-06 18:40:04,890:INFO:Checking exceptions
2024-06-06 18:40:04,894:INFO:Importing libraries
2024-06-06 18:40:04,894:INFO:Copying training dataset
2024-06-06 18:40:05,454:INFO:Defining folds
2024-06-06 18:40:05,455:INFO:Declaring metric variables
2024-06-06 18:40:05,455:INFO:Importing untrained model
2024-06-06 18:40:05,455:INFO:Declaring custom model
2024-06-06 18:40:05,458:INFO:Extreme Gradient Boosting Imported successfully
2024-06-06 18:40:05,459:INFO:Cross validation set to False
2024-06-06 18:40:05,459:INFO:Fitting Model
2024-06-06 18:40:10,336:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-06-06 18:40:10,337:INFO:create_model() successfully completed......................................
2024-06-06 18:40:10,715:INFO:_master_model_container: 2
2024-06-06 18:40:10,715:INFO:_display_container: 2
2024-06-06 18:40:10,717:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-06-06 18:40:10,717:INFO:compare_models() successfully completed......................................
2024-06-07 13:57:20,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-07 13:57:20,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-07 13:57:20,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-07 13:57:20,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:09:34,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:09:34,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:09:34,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:09:34,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:09:56,320:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\1394510014.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_tratado.corr()

2024-06-08 13:13:13,167:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\4028023209.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:13:37,687:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\655760912.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:13:47,415:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\3532754480.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:15:37,801:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\1216598093.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:15:45,810:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\825426261.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:16:02,023:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\3039158405.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:16:09,557:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_16188\1881577981.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlacao_df = df_corr_teste.corr()

2024-06-08 13:43:59,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:43:59,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:43:59,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 13:43:59,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-08 14:49:24,057:INFO:PyCaret RegressionExperiment
2024-06-08 14:49:24,060:INFO:Logging name: reg-default-name
2024-06-08 14:49:24,060:INFO:ML Usecase: MLUsecase.REGRESSION
2024-06-08 14:49:24,061:INFO:version 3.3.2
2024-06-08 14:49:24,061:INFO:Initializing setup()
2024-06-08 14:49:24,062:INFO:self.USI: a60e
2024-06-08 14:49:24,062:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'html_param', 'X_test', 'n_jobs_param', 'transform_target_param', 'fold_groups_param', 'target_param', 'fold_shuffle_param', 'data', 'exp_id', 'log_plots_param', 'seed', 'exp_name_log', 'gpu_param', '_available_plots', 'logging_param', 'pipeline', 'fold_generator', 'idx', 'X', 'gpu_n_jobs_param', 'y_test', 'memory', 'y', 'X_train', 'USI'}
2024-06-08 14:49:24,063:INFO:Checking environment
2024-06-08 14:49:24,063:INFO:python_version: 3.11.5
2024-06-08 14:49:24,063:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-08 14:49:24,064:INFO:machine: AMD64
2024-06-08 14:49:24,064:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-08 14:49:24,064:INFO:Memory: svmem(total=21420621824, available=5994131456, percent=72.0, used=15426490368, free=5994131456)
2024-06-08 14:49:24,064:INFO:Physical Core: 4
2024-06-08 14:49:24,065:INFO:Logical Core: 4
2024-06-08 14:49:24,065:INFO:Checking libraries
2024-06-08 14:49:24,065:INFO:System:
2024-06-08 14:49:24,066:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-08 14:49:24,066:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-08 14:49:24,066:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-08 14:49:24,066:INFO:PyCaret required dependencies:
2024-06-08 14:49:27,190:INFO:                 pip: 23.2.1
2024-06-08 14:49:27,190:INFO:          setuptools: 68.0.0
2024-06-08 14:49:27,199:INFO:             pycaret: 3.3.2
2024-06-08 14:49:27,218:INFO:             IPython: 8.20.0
2024-06-08 14:49:27,218:INFO:          ipywidgets: 8.1.2
2024-06-08 14:49:27,219:INFO:                tqdm: 4.65.0
2024-06-08 14:49:27,219:INFO:               numpy: 1.26.4
2024-06-08 14:49:27,219:INFO:              pandas: 1.5.3
2024-06-08 14:49:27,219:INFO:              jinja2: 3.1.3
2024-06-08 14:49:27,220:INFO:               scipy: 1.11.4
2024-06-08 14:49:27,220:INFO:              joblib: 1.2.0
2024-06-08 14:49:27,220:INFO:             sklearn: 1.4.2
2024-06-08 14:49:27,220:INFO:                pyod: 2.0.0
2024-06-08 14:49:27,221:INFO:            imblearn: 0.12.3
2024-06-08 14:49:27,221:INFO:   category_encoders: 2.6.3
2024-06-08 14:49:27,221:INFO:            lightgbm: 4.3.0
2024-06-08 14:49:27,221:INFO:               numba: 0.59.1
2024-06-08 14:49:27,222:INFO:            requests: 2.31.0
2024-06-08 14:49:27,222:INFO:          matplotlib: 3.7.5
2024-06-08 14:49:27,223:INFO:          scikitplot: 0.3.7
2024-06-08 14:49:27,223:INFO:         yellowbrick: 1.5
2024-06-08 14:49:27,223:INFO:              plotly: 5.19.0
2024-06-08 14:49:27,223:INFO:    plotly-resampler: Not installed
2024-06-08 14:49:27,224:INFO:             kaleido: 0.2.1
2024-06-08 14:49:27,224:INFO:           schemdraw: 0.15
2024-06-08 14:49:27,224:INFO:         statsmodels: 0.14.0
2024-06-08 14:49:27,224:INFO:              sktime: 0.26.0
2024-06-08 14:49:27,224:INFO:               tbats: 1.1.3
2024-06-08 14:49:27,225:INFO:            pmdarima: 2.0.4
2024-06-08 14:49:27,225:INFO:              psutil: 5.9.0
2024-06-08 14:49:27,225:INFO:          markupsafe: 2.1.3
2024-06-08 14:49:27,226:INFO:             pickle5: Not installed
2024-06-08 14:49:27,226:INFO:         cloudpickle: 2.2.1
2024-06-08 14:49:27,226:INFO:         deprecation: 2.1.0
2024-06-08 14:49:27,226:INFO:              xxhash: 2.0.2
2024-06-08 14:49:27,226:INFO:           wurlitzer: Not installed
2024-06-08 14:49:27,227:INFO:PyCaret optional dependencies:
2024-06-08 14:49:27,455:INFO:                shap: Not installed
2024-06-08 14:49:27,455:INFO:           interpret: Not installed
2024-06-08 14:49:27,455:INFO:                umap: Not installed
2024-06-08 14:49:27,456:INFO:     ydata_profiling: Not installed
2024-06-08 14:49:27,456:INFO:  explainerdashboard: Not installed
2024-06-08 14:49:27,456:INFO:             autoviz: Not installed
2024-06-08 14:49:27,456:INFO:           fairlearn: Not installed
2024-06-08 14:49:27,457:INFO:          deepchecks: Not installed
2024-06-08 14:49:27,457:INFO:             xgboost: 2.0.3
2024-06-08 14:49:27,457:INFO:            catboost: Not installed
2024-06-08 14:49:27,457:INFO:              kmodes: Not installed
2024-06-08 14:49:27,457:INFO:             mlxtend: Not installed
2024-06-08 14:49:27,458:INFO:       statsforecast: Not installed
2024-06-08 14:49:27,458:INFO:        tune_sklearn: Not installed
2024-06-08 14:49:27,458:INFO:                 ray: Not installed
2024-06-08 14:49:27,458:INFO:            hyperopt: Not installed
2024-06-08 14:49:27,458:INFO:              optuna: Not installed
2024-06-08 14:49:27,459:INFO:               skopt: Not installed
2024-06-08 14:49:27,459:INFO:              mlflow: Not installed
2024-06-08 14:49:27,459:INFO:              gradio: Not installed
2024-06-08 14:49:27,459:INFO:             fastapi: Not installed
2024-06-08 14:49:27,459:INFO:             uvicorn: Not installed
2024-06-08 14:49:27,460:INFO:              m2cgen: Not installed
2024-06-08 14:49:27,460:INFO:           evidently: Not installed
2024-06-08 14:49:27,460:INFO:               fugue: Not installed
2024-06-08 14:49:27,460:INFO:           streamlit: Not installed
2024-06-08 14:49:27,460:INFO:             prophet: Not installed
2024-06-08 14:49:27,460:INFO:None
2024-06-08 14:49:27,461:INFO:Set up data.
2024-06-08 14:49:28,177:INFO:Set up folding strategy.
2024-06-08 14:49:28,198:INFO:Set up train/test split.
2024-06-08 14:49:28,997:INFO:Set up index.
2024-06-08 14:49:29,045:INFO:Assigning column types.
2024-06-08 14:49:29,415:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-08 14:49:29,416:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-08 14:49:29,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-08 14:49:29,434:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:29,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,029:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:30,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:30,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,044:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,648:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:30,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:30,653:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-06-08 14:49:30,662:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-08 14:49:30,670:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,272:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:31,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:31,287:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:31,919:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:31,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:31,925:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-06-08 14:49:31,942:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:32,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:32,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:32,550:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:32,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:32,574:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-06-08 14:49:33,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:33,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:33,142:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:33,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:33,147:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-06-08 14:49:33,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:33,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:33,830:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:33,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:34,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:34,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:49:34,617:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:34,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:34,626:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-08 14:49:35,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:35,265:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:35,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:35,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-06-08 14:49:35,940:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:35,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:35,949:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-06-08 14:49:36,632:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:36,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:37,291:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:37,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:37,301:INFO:Preparing preprocessing pipeline...
2024-06-08 14:49:37,302:INFO:Set up simple imputation.
2024-06-08 14:49:38,644:INFO:Finished creating preprocessing pipeline.
2024-06-08 14:49:38,651:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-06-08 14:49:38,652:INFO:Creating final display dataframe.
2024-06-08 14:49:40,966:INFO:Setup _display_container:                     Description             Value
0                    Session id               181
1                        Target            STATUS
2                   Target type        Regression
3           Original data shape      (777552, 35)
4        Transformed data shape      (777552, 35)
5   Transformed train set shape      (544286, 35)
6    Transformed test set shape      (233266, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a60e
2024-06-08 14:49:41,654:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:41,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:42,450:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:49:42,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:49:42,463:INFO:setup() successfully completed in 18.46s...............
2024-06-08 14:51:47,327:INFO:PyCaret ClassificationExperiment
2024-06-08 14:51:47,425:INFO:Logging name: clf-default-name
2024-06-08 14:51:47,425:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-08 14:51:47,425:INFO:version 3.3.2
2024-06-08 14:51:47,426:INFO:Initializing setup()
2024-06-08 14:51:47,426:INFO:self.USI: 2900
2024-06-08 14:51:47,426:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'html_param', 'X_test', 'n_jobs_param', 'fold_groups_param', 'target_param', 'fold_shuffle_param', 'data', 'exp_id', 'log_plots_param', 'seed', 'exp_name_log', 'gpu_param', '_available_plots', 'logging_param', 'pipeline', 'fold_generator', 'idx', 'is_multiclass', 'X', 'gpu_n_jobs_param', 'y_test', 'memory', 'fix_imbalance', 'y', 'X_train', 'USI'}
2024-06-08 14:51:47,426:INFO:Checking environment
2024-06-08 14:51:47,427:INFO:python_version: 3.11.5
2024-06-08 14:51:47,427:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-08 14:51:47,427:INFO:machine: AMD64
2024-06-08 14:51:47,427:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-08 14:51:47,429:INFO:Memory: svmem(total=21420621824, available=5789827072, percent=73.0, used=15630794752, free=5789827072)
2024-06-08 14:51:47,429:INFO:Physical Core: 4
2024-06-08 14:51:47,430:INFO:Logical Core: 4
2024-06-08 14:51:47,431:INFO:Checking libraries
2024-06-08 14:51:47,431:INFO:System:
2024-06-08 14:51:47,431:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-08 14:51:47,432:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-08 14:51:47,432:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-08 14:51:47,432:INFO:PyCaret required dependencies:
2024-06-08 14:51:47,432:INFO:                 pip: 23.2.1
2024-06-08 14:51:47,433:INFO:          setuptools: 68.0.0
2024-06-08 14:51:47,433:INFO:             pycaret: 3.3.2
2024-06-08 14:51:47,433:INFO:             IPython: 8.20.0
2024-06-08 14:51:47,433:INFO:          ipywidgets: 8.1.2
2024-06-08 14:51:47,434:INFO:                tqdm: 4.65.0
2024-06-08 14:51:47,434:INFO:               numpy: 1.26.4
2024-06-08 14:51:47,434:INFO:              pandas: 1.5.3
2024-06-08 14:51:47,435:INFO:              jinja2: 3.1.3
2024-06-08 14:51:47,435:INFO:               scipy: 1.11.4
2024-06-08 14:51:47,435:INFO:              joblib: 1.2.0
2024-06-08 14:51:47,435:INFO:             sklearn: 1.4.2
2024-06-08 14:51:47,436:INFO:                pyod: 2.0.0
2024-06-08 14:51:47,438:INFO:            imblearn: 0.12.3
2024-06-08 14:51:47,439:INFO:   category_encoders: 2.6.3
2024-06-08 14:51:47,440:INFO:            lightgbm: 4.3.0
2024-06-08 14:51:47,440:INFO:               numba: 0.59.1
2024-06-08 14:51:47,441:INFO:            requests: 2.31.0
2024-06-08 14:51:47,441:INFO:          matplotlib: 3.7.5
2024-06-08 14:51:47,441:INFO:          scikitplot: 0.3.7
2024-06-08 14:51:47,442:INFO:         yellowbrick: 1.5
2024-06-08 14:51:47,442:INFO:              plotly: 5.19.0
2024-06-08 14:51:47,442:INFO:    plotly-resampler: Not installed
2024-06-08 14:51:47,443:INFO:             kaleido: 0.2.1
2024-06-08 14:51:47,443:INFO:           schemdraw: 0.15
2024-06-08 14:51:47,443:INFO:         statsmodels: 0.14.0
2024-06-08 14:51:47,443:INFO:              sktime: 0.26.0
2024-06-08 14:51:47,444:INFO:               tbats: 1.1.3
2024-06-08 14:51:47,444:INFO:            pmdarima: 2.0.4
2024-06-08 14:51:47,445:INFO:              psutil: 5.9.0
2024-06-08 14:51:47,445:INFO:          markupsafe: 2.1.3
2024-06-08 14:51:47,445:INFO:             pickle5: Not installed
2024-06-08 14:51:47,445:INFO:         cloudpickle: 2.2.1
2024-06-08 14:51:47,446:INFO:         deprecation: 2.1.0
2024-06-08 14:51:47,446:INFO:              xxhash: 2.0.2
2024-06-08 14:51:47,446:INFO:           wurlitzer: Not installed
2024-06-08 14:51:47,447:INFO:PyCaret optional dependencies:
2024-06-08 14:51:47,447:INFO:                shap: Not installed
2024-06-08 14:51:47,447:INFO:           interpret: Not installed
2024-06-08 14:51:47,448:INFO:                umap: Not installed
2024-06-08 14:51:47,448:INFO:     ydata_profiling: Not installed
2024-06-08 14:51:47,448:INFO:  explainerdashboard: Not installed
2024-06-08 14:51:47,449:INFO:             autoviz: Not installed
2024-06-08 14:51:47,449:INFO:           fairlearn: Not installed
2024-06-08 14:51:47,449:INFO:          deepchecks: Not installed
2024-06-08 14:51:47,450:INFO:             xgboost: 2.0.3
2024-06-08 14:51:47,450:INFO:            catboost: Not installed
2024-06-08 14:51:47,451:INFO:              kmodes: Not installed
2024-06-08 14:51:47,451:INFO:             mlxtend: Not installed
2024-06-08 14:51:47,451:INFO:       statsforecast: Not installed
2024-06-08 14:51:47,451:INFO:        tune_sklearn: Not installed
2024-06-08 14:51:47,452:INFO:                 ray: Not installed
2024-06-08 14:51:47,452:INFO:            hyperopt: Not installed
2024-06-08 14:51:47,453:INFO:              optuna: Not installed
2024-06-08 14:51:47,455:INFO:               skopt: Not installed
2024-06-08 14:51:47,456:INFO:              mlflow: Not installed
2024-06-08 14:51:47,457:INFO:              gradio: Not installed
2024-06-08 14:51:47,457:INFO:             fastapi: Not installed
2024-06-08 14:51:47,457:INFO:             uvicorn: Not installed
2024-06-08 14:51:47,458:INFO:              m2cgen: Not installed
2024-06-08 14:51:47,458:INFO:           evidently: Not installed
2024-06-08 14:51:47,458:INFO:               fugue: Not installed
2024-06-08 14:51:47,459:INFO:           streamlit: Not installed
2024-06-08 14:51:47,459:INFO:             prophet: Not installed
2024-06-08 14:51:47,459:INFO:None
2024-06-08 14:51:47,459:INFO:Set up data.
2024-06-08 14:51:47,936:INFO:Set up folding strategy.
2024-06-08 14:51:47,936:INFO:Set up train/test split.
2024-06-08 14:51:48,719:INFO:Set up index.
2024-06-08 14:51:48,762:INFO:Assigning column types.
2024-06-08 14:51:49,077:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-08 14:51:49,159:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,166:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,234:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,323:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,372:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,377:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-08 14:51:49,453:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,504:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,583:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 14:51:49,629:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,634:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-08 14:51:49,762:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,893:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:49,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:49,900:INFO:Preparing preprocessing pipeline...
2024-06-08 14:51:49,956:INFO:Set up simple imputation.
2024-06-08 14:51:51,015:INFO:Finished creating preprocessing pipeline.
2024-06-08 14:51:51,021:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-08 14:51:51,021:INFO:Creating final display dataframe.
2024-06-08 14:51:53,412:INFO:Setup _display_container:                     Description             Value
0                    Session id               248
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 35)
4        Transformed data shape      (777552, 35)
5   Transformed train set shape      (544286, 35)
6    Transformed test set shape      (233266, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              2900
2024-06-08 14:51:53,606:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:53,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:53,769:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 14:51:53,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 14:51:53,777:INFO:setup() successfully completed in 6.49s...............
2024-06-08 14:59:28,120:INFO:Initializing create_model()
2024-06-08 14:59:28,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905C367710>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-08 14:59:28,174:INFO:Checking exceptions
2024-06-08 14:59:28,232:INFO:Importing libraries
2024-06-08 14:59:28,257:INFO:Copying training dataset
2024-06-08 14:59:29,035:INFO:Defining folds
2024-06-08 14:59:29,035:INFO:Declaring metric variables
2024-06-08 14:59:29,040:INFO:Importing untrained model
2024-06-08 14:59:29,046:INFO:Random Forest Classifier Imported successfully
2024-06-08 14:59:29,059:INFO:Starting cross validation
2024-06-08 14:59:29,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-08 15:12:22,474:INFO:Calculating mean and std
2024-06-08 15:12:22,691:INFO:Creating metrics dataframe
2024-06-08 15:12:23,089:INFO:Finalizing model
2024-06-08 15:13:46,881:INFO:Uploading results into container
2024-06-08 15:13:46,897:INFO:Uploading model into container now
2024-06-08 15:13:46,982:INFO:_master_model_container: 1
2024-06-08 15:13:46,983:INFO:_display_container: 2
2024-06-08 15:13:46,989:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=248, verbose=0,
                       warm_start=False)
2024-06-08 15:13:46,990:INFO:create_model() successfully completed......................................
2024-06-08 15:18:58,669:INFO:Initializing plot_model()
2024-06-08 15:18:58,669:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905C367710>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=248, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 15:18:58,670:INFO:Checking exceptions
2024-06-08 15:18:59,755:INFO:Preloading libraries
2024-06-08 15:19:02,376:INFO:Copying training dataset
2024-06-08 15:19:02,376:INFO:Plot type: confusion_matrix
2024-06-08 15:19:04,670:INFO:Fitting Model
2024-06-08 15:19:04,674:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 15:19:04,684:INFO:Scoring test/hold-out set
2024-06-08 15:19:20,520:INFO:Visual Rendered Successfully
2024-06-08 15:19:20,706:INFO:plot_model() successfully completed......................................
2024-06-08 15:21:12,463:INFO:Initializing predict_model()
2024-06-08 15:21:12,489:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905C367710>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=248, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002902C1965C0>)
2024-06-08 15:21:12,490:INFO:Checking exceptions
2024-06-08 15:21:12,490:INFO:Preloading libraries
2024-06-08 15:41:19,527:INFO:PyCaret ClassificationExperiment
2024-06-08 15:41:19,534:INFO:Logging name: clf-default-name
2024-06-08 15:41:19,545:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-08 15:41:19,545:INFO:version 3.3.2
2024-06-08 15:41:19,546:INFO:Initializing setup()
2024-06-08 15:41:19,546:INFO:self.USI: 91e6
2024-06-08 15:41:19,547:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'html_param', 'X_test', 'n_jobs_param', 'fold_groups_param', 'target_param', 'fold_shuffle_param', 'data', 'exp_id', 'log_plots_param', 'seed', 'exp_name_log', 'gpu_param', '_available_plots', 'logging_param', 'pipeline', 'fold_generator', 'idx', 'is_multiclass', 'X', 'gpu_n_jobs_param', 'y_test', 'memory', 'fix_imbalance', 'y', 'X_train', 'USI'}
2024-06-08 15:41:19,552:INFO:Checking environment
2024-06-08 15:41:19,553:INFO:python_version: 3.11.5
2024-06-08 15:41:19,553:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-08 15:41:19,553:INFO:machine: AMD64
2024-06-08 15:41:19,554:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-08 15:41:19,555:INFO:Memory: svmem(total=21420621824, available=6432280576, percent=70.0, used=14988341248, free=6432280576)
2024-06-08 15:41:19,555:INFO:Physical Core: 4
2024-06-08 15:41:19,556:INFO:Logical Core: 4
2024-06-08 15:41:19,557:INFO:Checking libraries
2024-06-08 15:41:19,557:INFO:System:
2024-06-08 15:41:19,558:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-08 15:41:19,558:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-08 15:41:19,559:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-08 15:41:19,559:INFO:PyCaret required dependencies:
2024-06-08 15:41:19,560:INFO:                 pip: 23.2.1
2024-06-08 15:41:19,560:INFO:          setuptools: 68.0.0
2024-06-08 15:41:19,561:INFO:             pycaret: 3.3.2
2024-06-08 15:41:19,561:INFO:             IPython: 8.20.0
2024-06-08 15:41:19,561:INFO:          ipywidgets: 8.1.2
2024-06-08 15:41:19,562:INFO:                tqdm: 4.65.0
2024-06-08 15:41:19,563:INFO:               numpy: 1.26.4
2024-06-08 15:41:19,563:INFO:              pandas: 1.5.3
2024-06-08 15:41:19,563:INFO:              jinja2: 3.1.3
2024-06-08 15:41:19,567:INFO:               scipy: 1.11.4
2024-06-08 15:41:19,569:INFO:              joblib: 1.2.0
2024-06-08 15:41:19,569:INFO:             sklearn: 1.4.2
2024-06-08 15:41:19,570:INFO:                pyod: 2.0.0
2024-06-08 15:41:19,570:INFO:            imblearn: 0.12.3
2024-06-08 15:41:19,571:INFO:   category_encoders: 2.6.3
2024-06-08 15:41:19,571:INFO:            lightgbm: 4.3.0
2024-06-08 15:41:19,572:INFO:               numba: 0.59.1
2024-06-08 15:41:19,573:INFO:            requests: 2.31.0
2024-06-08 15:41:19,573:INFO:          matplotlib: 3.7.5
2024-06-08 15:41:19,574:INFO:          scikitplot: 0.3.7
2024-06-08 15:41:19,575:INFO:         yellowbrick: 1.5
2024-06-08 15:41:19,575:INFO:              plotly: 5.19.0
2024-06-08 15:41:19,575:INFO:    plotly-resampler: Not installed
2024-06-08 15:41:19,576:INFO:             kaleido: 0.2.1
2024-06-08 15:41:19,576:INFO:           schemdraw: 0.15
2024-06-08 15:41:19,577:INFO:         statsmodels: 0.14.0
2024-06-08 15:41:19,577:INFO:              sktime: 0.26.0
2024-06-08 15:41:19,577:INFO:               tbats: 1.1.3
2024-06-08 15:41:19,578:INFO:            pmdarima: 2.0.4
2024-06-08 15:41:19,578:INFO:              psutil: 5.9.0
2024-06-08 15:41:19,578:INFO:          markupsafe: 2.1.3
2024-06-08 15:41:19,578:INFO:             pickle5: Not installed
2024-06-08 15:41:19,579:INFO:         cloudpickle: 2.2.1
2024-06-08 15:41:19,579:INFO:         deprecation: 2.1.0
2024-06-08 15:41:19,579:INFO:              xxhash: 2.0.2
2024-06-08 15:41:19,580:INFO:           wurlitzer: Not installed
2024-06-08 15:41:19,581:INFO:PyCaret optional dependencies:
2024-06-08 15:41:19,585:INFO:                shap: Not installed
2024-06-08 15:41:19,585:INFO:           interpret: Not installed
2024-06-08 15:41:19,585:INFO:                umap: Not installed
2024-06-08 15:41:19,586:INFO:     ydata_profiling: Not installed
2024-06-08 15:41:19,586:INFO:  explainerdashboard: Not installed
2024-06-08 15:41:19,586:INFO:             autoviz: Not installed
2024-06-08 15:41:19,586:INFO:           fairlearn: Not installed
2024-06-08 15:41:19,586:INFO:          deepchecks: Not installed
2024-06-08 15:41:19,587:INFO:             xgboost: 2.0.3
2024-06-08 15:41:19,587:INFO:            catboost: Not installed
2024-06-08 15:41:19,587:INFO:              kmodes: Not installed
2024-06-08 15:41:19,588:INFO:             mlxtend: Not installed
2024-06-08 15:41:19,588:INFO:       statsforecast: Not installed
2024-06-08 15:41:19,588:INFO:        tune_sklearn: Not installed
2024-06-08 15:41:19,588:INFO:                 ray: Not installed
2024-06-08 15:41:19,589:INFO:            hyperopt: Not installed
2024-06-08 15:41:19,589:INFO:              optuna: Not installed
2024-06-08 15:41:19,590:INFO:               skopt: Not installed
2024-06-08 15:41:19,590:INFO:              mlflow: Not installed
2024-06-08 15:41:19,591:INFO:              gradio: Not installed
2024-06-08 15:41:19,591:INFO:             fastapi: Not installed
2024-06-08 15:41:19,591:INFO:             uvicorn: Not installed
2024-06-08 15:41:19,592:INFO:              m2cgen: Not installed
2024-06-08 15:41:19,592:INFO:           evidently: Not installed
2024-06-08 15:41:19,592:INFO:               fugue: Not installed
2024-06-08 15:41:19,593:INFO:           streamlit: Not installed
2024-06-08 15:41:19,593:INFO:             prophet: Not installed
2024-06-08 15:41:19,593:INFO:None
2024-06-08 15:41:19,593:INFO:Set up data.
2024-06-08 15:41:21,442:INFO:Set up folding strategy.
2024-06-08 15:41:21,442:INFO:Set up train/test split.
2024-06-08 15:41:22,382:INFO:Set up index.
2024-06-08 15:41:22,448:INFO:Assigning column types.
2024-06-08 15:41:22,772:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-08 15:41:22,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 15:41:22,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:41:22,909:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:22,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:22,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 15:41:22,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:41:23,046:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:23,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:23,053:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-08 15:41:23,138:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:41:23,188:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:23,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:23,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:41:23,325:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:23,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:23,331:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-08 15:41:23,464:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:23,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:23,594:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:23,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:23,602:INFO:Preparing preprocessing pipeline...
2024-06-08 15:41:23,655:INFO:Set up simple imputation.
2024-06-08 15:41:24,646:INFO:Finished creating preprocessing pipeline.
2024-06-08 15:41:24,653:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-08 15:41:24,653:INFO:Creating final display dataframe.
2024-06-08 15:41:26,659:INFO:Setup _display_container:                     Description             Value
0                    Session id              7797
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 35)
4        Transformed data shape      (777552, 35)
5   Transformed train set shape      (544286, 35)
6    Transformed test set shape      (233266, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              91e6
2024-06-08 15:41:26,813:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:26,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:26,952:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:41:26,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:41:26,960:INFO:setup() successfully completed in 7.54s...............
2024-06-08 15:41:40,365:INFO:Initializing create_model()
2024-06-08 15:41:40,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905C1F74D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-08 15:41:40,376:INFO:Checking exceptions
2024-06-08 15:41:40,413:INFO:Importing libraries
2024-06-08 15:41:40,413:INFO:Copying training dataset
2024-06-08 15:41:40,972:INFO:Defining folds
2024-06-08 15:41:40,972:INFO:Declaring metric variables
2024-06-08 15:41:40,979:INFO:Importing untrained model
2024-06-08 15:41:40,983:INFO:Random Forest Classifier Imported successfully
2024-06-08 15:41:40,994:INFO:Starting cross validation
2024-06-08 15:41:40,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-08 15:52:28,331:INFO:Calculating mean and std
2024-06-08 15:52:28,342:INFO:Creating metrics dataframe
2024-06-08 15:52:28,369:INFO:Finalizing model
2024-06-08 15:53:45,995:INFO:Uploading results into container
2024-06-08 15:53:45,997:INFO:Uploading model into container now
2024-06-08 15:53:46,015:INFO:_master_model_container: 1
2024-06-08 15:53:46,019:INFO:_display_container: 2
2024-06-08 15:53:46,020:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7797, verbose=0,
                       warm_start=False)
2024-06-08 15:53:46,025:INFO:create_model() successfully completed......................................
2024-06-08 15:58:20,995:INFO:PyCaret ClassificationExperiment
2024-06-08 15:58:21,301:INFO:Logging name: clf-default-name
2024-06-08 15:58:21,301:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-08 15:58:21,302:INFO:version 3.3.2
2024-06-08 15:58:21,302:INFO:Initializing setup()
2024-06-08 15:58:21,303:INFO:self.USI: 0da1
2024-06-08 15:58:21,303:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'html_param', 'X_test', 'n_jobs_param', 'fold_groups_param', 'target_param', 'fold_shuffle_param', 'data', 'exp_id', 'log_plots_param', 'seed', 'exp_name_log', 'gpu_param', '_available_plots', 'logging_param', 'pipeline', 'fold_generator', 'idx', 'is_multiclass', 'X', 'gpu_n_jobs_param', 'y_test', 'memory', 'fix_imbalance', 'y', 'X_train', 'USI'}
2024-06-08 15:58:21,303:INFO:Checking environment
2024-06-08 15:58:21,304:INFO:python_version: 3.11.5
2024-06-08 15:58:21,304:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-06-08 15:58:21,304:INFO:machine: AMD64
2024-06-08 15:58:21,305:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-08 15:58:21,305:INFO:Memory: svmem(total=21420621824, available=7528632320, percent=64.9, used=13891989504, free=7528632320)
2024-06-08 15:58:21,305:INFO:Physical Core: 4
2024-06-08 15:58:21,306:INFO:Logical Core: 4
2024-06-08 15:58:21,306:INFO:Checking libraries
2024-06-08 15:58:21,306:INFO:System:
2024-06-08 15:58:21,306:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-06-08 15:58:21,307:INFO:executable: c:\Users\user\anaconda3\python.exe
2024-06-08 15:58:21,307:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-08 15:58:21,307:INFO:PyCaret required dependencies:
2024-06-08 15:58:21,308:INFO:                 pip: 23.2.1
2024-06-08 15:58:21,308:INFO:          setuptools: 68.0.0
2024-06-08 15:58:21,308:INFO:             pycaret: 3.3.2
2024-06-08 15:58:21,308:INFO:             IPython: 8.20.0
2024-06-08 15:58:21,309:INFO:          ipywidgets: 8.1.2
2024-06-08 15:58:21,309:INFO:                tqdm: 4.65.0
2024-06-08 15:58:21,309:INFO:               numpy: 1.26.4
2024-06-08 15:58:21,310:INFO:              pandas: 1.5.3
2024-06-08 15:58:21,310:INFO:              jinja2: 3.1.3
2024-06-08 15:58:21,310:INFO:               scipy: 1.11.4
2024-06-08 15:58:21,310:INFO:              joblib: 1.2.0
2024-06-08 15:58:21,311:INFO:             sklearn: 1.4.2
2024-06-08 15:58:21,313:INFO:                pyod: 2.0.0
2024-06-08 15:58:21,313:INFO:            imblearn: 0.12.3
2024-06-08 15:58:21,314:INFO:   category_encoders: 2.6.3
2024-06-08 15:58:21,314:INFO:            lightgbm: 4.3.0
2024-06-08 15:58:21,314:INFO:               numba: 0.59.1
2024-06-08 15:58:21,315:INFO:            requests: 2.31.0
2024-06-08 15:58:21,315:INFO:          matplotlib: 3.7.5
2024-06-08 15:58:21,316:INFO:          scikitplot: 0.3.7
2024-06-08 15:58:21,316:INFO:         yellowbrick: 1.5
2024-06-08 15:58:21,316:INFO:              plotly: 5.19.0
2024-06-08 15:58:21,317:INFO:    plotly-resampler: Not installed
2024-06-08 15:58:21,317:INFO:             kaleido: 0.2.1
2024-06-08 15:58:21,317:INFO:           schemdraw: 0.15
2024-06-08 15:58:21,318:INFO:         statsmodels: 0.14.0
2024-06-08 15:58:21,318:INFO:              sktime: 0.26.0
2024-06-08 15:58:21,318:INFO:               tbats: 1.1.3
2024-06-08 15:58:21,318:INFO:            pmdarima: 2.0.4
2024-06-08 15:58:21,319:INFO:              psutil: 5.9.0
2024-06-08 15:58:21,319:INFO:          markupsafe: 2.1.3
2024-06-08 15:58:21,320:INFO:             pickle5: Not installed
2024-06-08 15:58:21,320:INFO:         cloudpickle: 2.2.1
2024-06-08 15:58:21,320:INFO:         deprecation: 2.1.0
2024-06-08 15:58:21,320:INFO:              xxhash: 2.0.2
2024-06-08 15:58:21,321:INFO:           wurlitzer: Not installed
2024-06-08 15:58:21,321:INFO:PyCaret optional dependencies:
2024-06-08 15:58:21,321:INFO:                shap: Not installed
2024-06-08 15:58:21,321:INFO:           interpret: Not installed
2024-06-08 15:58:21,322:INFO:                umap: Not installed
2024-06-08 15:58:21,322:INFO:     ydata_profiling: Not installed
2024-06-08 15:58:21,322:INFO:  explainerdashboard: Not installed
2024-06-08 15:58:21,322:INFO:             autoviz: Not installed
2024-06-08 15:58:21,322:INFO:           fairlearn: Not installed
2024-06-08 15:58:21,323:INFO:          deepchecks: Not installed
2024-06-08 15:58:21,323:INFO:             xgboost: 2.0.3
2024-06-08 15:58:21,323:INFO:            catboost: Not installed
2024-06-08 15:58:21,323:INFO:              kmodes: Not installed
2024-06-08 15:58:21,324:INFO:             mlxtend: Not installed
2024-06-08 15:58:21,324:INFO:       statsforecast: Not installed
2024-06-08 15:58:21,324:INFO:        tune_sklearn: Not installed
2024-06-08 15:58:21,325:INFO:                 ray: Not installed
2024-06-08 15:58:21,325:INFO:            hyperopt: Not installed
2024-06-08 15:58:21,325:INFO:              optuna: Not installed
2024-06-08 15:58:21,325:INFO:               skopt: Not installed
2024-06-08 15:58:21,326:INFO:              mlflow: Not installed
2024-06-08 15:58:21,326:INFO:              gradio: Not installed
2024-06-08 15:58:21,326:INFO:             fastapi: Not installed
2024-06-08 15:58:21,327:INFO:             uvicorn: Not installed
2024-06-08 15:58:21,327:INFO:              m2cgen: Not installed
2024-06-08 15:58:21,327:INFO:           evidently: Not installed
2024-06-08 15:58:21,327:INFO:               fugue: Not installed
2024-06-08 15:58:21,328:INFO:           streamlit: Not installed
2024-06-08 15:58:21,328:INFO:             prophet: Not installed
2024-06-08 15:58:21,328:INFO:None
2024-06-08 15:58:21,329:INFO:Set up data.
2024-06-08 15:58:21,841:INFO:Set up folding strategy.
2024-06-08 15:58:21,842:INFO:Set up train/test split.
2024-06-08 15:58:22,982:INFO:Set up index.
2024-06-08 15:58:23,045:INFO:Assigning column types.
2024-06-08 15:58:23,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-08 15:58:23,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 15:58:23,536:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:58:23,595:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:23,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:23,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-08 15:58:23,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:58:23,769:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:23,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:23,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-08 15:58:23,855:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:58:23,903:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:23,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:23,990:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-08 15:58:24,042:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:24,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:24,050:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-08 15:58:24,181:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:24,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:24,323:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:24,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:24,330:INFO:Preparing preprocessing pipeline...
2024-06-08 15:58:24,385:INFO:Set up simple imputation.
2024-06-08 15:58:25,525:INFO:Finished creating preprocessing pipeline.
2024-06-08 15:58:25,531:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12',
                                             '13', '14', '15', '16', '17', '18',
                                             '19', '20', '21', '22', '23', '24',
                                             '25', '26', '27', '28', '29', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-06-08 15:58:25,531:INFO:Creating final display dataframe.
2024-06-08 15:58:27,859:INFO:Setup _display_container:                     Description             Value
0                    Session id              3560
1                        Target            STATUS
2                   Target type        Multiclass
3           Original data shape      (777552, 36)
4        Transformed data shape      (777552, 36)
5   Transformed train set shape      (544286, 36)
6    Transformed test set shape      (233266, 36)
7              Numeric features                35
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0da1
2024-06-08 15:58:28,027:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:28,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:28,161:INFO:Soft dependency imported: xgboost: 2.0.3
2024-06-08 15:58:28,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-08 15:58:28,167:INFO:setup() successfully completed in 7.24s...............
2024-06-08 15:58:35,630:INFO:Initializing create_model()
2024-06-08 15:58:35,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-08 15:58:35,691:INFO:Checking exceptions
2024-06-08 15:58:35,763:INFO:Importing libraries
2024-06-08 15:58:35,910:INFO:Copying training dataset
2024-06-08 15:58:36,500:INFO:Defining folds
2024-06-08 15:58:36,500:INFO:Declaring metric variables
2024-06-08 15:58:36,507:INFO:Importing untrained model
2024-06-08 15:58:36,514:INFO:Random Forest Classifier Imported successfully
2024-06-08 15:58:36,526:INFO:Starting cross validation
2024-06-08 15:58:36,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-08 16:08:29,258:INFO:Calculating mean and std
2024-06-08 16:08:29,372:INFO:Creating metrics dataframe
2024-06-08 16:08:29,631:INFO:Finalizing model
2024-06-08 16:09:27,681:INFO:Uploading results into container
2024-06-08 16:09:27,701:INFO:Uploading model into container now
2024-06-08 16:09:27,801:INFO:_master_model_container: 1
2024-06-08 16:09:27,802:INFO:_display_container: 2
2024-06-08 16:09:27,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False)
2024-06-08 16:09:27,818:INFO:create_model() successfully completed......................................
2024-06-08 16:10:55,534:INFO:Initializing predict_model()
2024-06-08 16:10:55,553:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002904A975760>)
2024-06-08 16:10:55,571:INFO:Checking exceptions
2024-06-08 16:10:55,573:INFO:Preloading libraries
2024-06-08 16:12:59,723:INFO:Initializing predict_model()
2024-06-08 16:12:59,724:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002904A3A9580>)
2024-06-08 16:12:59,726:INFO:Checking exceptions
2024-06-08 16:12:59,726:INFO:Preloading libraries
2024-06-08 16:13:18,867:INFO:Initializing plot_model()
2024-06-08 16:13:18,872:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=               0         1         2         3         4         5         6  \
720232 -1.537905  1.299579 -1.503682  0.794635 -0.272732 -1.467267 -0.798972   
550702 -1.603160 -0.769480 -1.503682 -0.591838  2.384245  0.711757 -0.488218   
716900 -1.538200 -0.769480 -1.503682 -0.591838 -1.049387  1.583366 -0.906172   
521298 -1.582486 -0.769480 -1.503682 -0.591838 -0.395362  0.188791  2.142968   
341678 -1.673675 -0.769480  0.665034 -0.591838  0.217787  0.101630 -0.238364   
...          ...       ...       ...       ...       ...       ...       ...   
130697 -1.737034 -0.769480  0.665034 -0.591838 -0.477115  1.321884 -0.906172   
748552 -1.527419  1.299579  0.665034  2.181108  0.340416 -0.247014 -0.810651   
33856  -1.769268  1.299579  0.665034 -0.591838  0.749182 -0.682818 -0.217091   
192354 -1.715693  1.299579  0.665034 -0.591838  1.362331  1.060401  0.212541   
226806 -1.707191  1.299579  0.665034 -0.591838  3.201776  0.973240  1.741700   

          7         8         9  ...        28        29        30        31  \
720232  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683  1.652748 -0.187223   
550702  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683  1.652748 -0.187223   
716900  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683 -0.605053 -0.187223   
521298  0.0  1.962508 -0.348346  ... -0.213262 -0.026683 -0.605053 -0.187223   
341678  0.0  1.962508 -0.348346  ... -0.213262 -0.026683 -0.605053 -0.187223   
...     ...       ...       ...  ...       ...       ...       ...       ...   
130697  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683  1.652748 -0.187223   
748552  0.0 -0.509552  2.870712  ... -0.213262 -0.026683  1.652748 -0.187223   
33856   0.0 -0.509552 -0.348346  ... -0.213262 -0.026683 -0.605053 -0.187223   
192354  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683  1.652748 -0.187223   
226806  0.0 -0.509552 -0.348346  ... -0.213262 -0.026683 -0.605053 -0.187223   

             32        33  MONTHS_BALANCE  STATUS  prediction_label  \
720232 -0.09656 -1.485667             -26       7                 7   
550702 -0.09656 -1.485667             -26       6                 6   
716900 -0.09656  0.673098             -14       6                 6   
521298 -0.09656  0.673098               0       6                 6   
341678 -0.09656  0.673098              -6       6                 6   
...         ...       ...             ...     ...               ...   
130697 -0.09656 -1.485667              -8       6                 6   
748552 -0.09656 -1.485667              -1       0                 6   
33856  -0.09656  0.673098             -21       7                 0   
192354 -0.09656 -1.485667              -3       0                 0   
226806 -0.09656  0.673098             -43       0                 0   

        prediction_score  
720232              1.00  
550702              1.00  
716900              0.98  
521298              1.00  
341678              0.97  
...                  ...  
130697              0.86  
748552              0.60  
33856               0.40  
192354              0.57  
226806              0.97  

[233266 rows x 38 columns], plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:13:18,873:INFO:Checking exceptions
2024-06-08 16:17:18,143:INFO:Initializing plot_model()
2024-06-08 16:17:18,147:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:17:18,148:INFO:Checking exceptions
2024-06-08 16:17:18,634:INFO:Preloading libraries
2024-06-08 16:17:21,050:INFO:Copying training dataset
2024-06-08 16:17:21,051:INFO:Plot type: confusion_matrix
2024-06-08 16:17:23,083:INFO:Fitting Model
2024-06-08 16:17:23,083:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:17:23,094:INFO:Scoring test/hold-out set
2024-06-08 16:17:39,533:INFO:Visual Rendered Successfully
2024-06-08 16:17:39,784:INFO:plot_model() successfully completed......................................
2024-06-08 16:20:15,111:INFO:Initializing plot_model()
2024-06-08 16:20:15,114:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:20:15,130:INFO:Checking exceptions
2024-06-08 16:20:15,529:INFO:Preloading libraries
2024-06-08 16:20:17,872:INFO:Copying training dataset
2024-06-08 16:20:17,872:INFO:Plot type: auc
2024-06-08 16:20:19,407:INFO:Fitting Model
2024-06-08 16:20:19,420:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:20:19,432:INFO:Scoring test/hold-out set
2024-06-08 16:20:31,790:INFO:Visual Rendered Successfully
2024-06-08 16:20:31,993:INFO:plot_model() successfully completed......................................
2024-06-08 16:21:32,837:INFO:Initializing plot_model()
2024-06-08 16:21:32,898:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:21:32,899:INFO:Checking exceptions
2024-06-08 16:21:33,237:INFO:Preloading libraries
2024-06-08 16:21:35,709:INFO:Copying training dataset
2024-06-08 16:21:35,709:INFO:Plot type: auc
2024-06-08 16:21:37,284:INFO:Fitting Model
2024-06-08 16:21:37,298:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:21:37,309:INFO:Scoring test/hold-out set
2024-06-08 16:21:51,630:INFO:Visual Rendered Successfully
2024-06-08 16:21:51,841:INFO:plot_model() successfully completed......................................
2024-06-08 16:22:04,598:INFO:Initializing plot_model()
2024-06-08 16:22:04,639:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:22:04,642:INFO:Checking exceptions
2024-06-08 16:22:05,025:INFO:Preloading libraries
2024-06-08 16:22:07,610:INFO:Copying training dataset
2024-06-08 16:22:07,611:INFO:Plot type: auc
2024-06-08 16:22:09,299:INFO:Fitting Model
2024-06-08 16:22:09,311:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:22:09,324:INFO:Scoring test/hold-out set
2024-06-08 16:22:22,267:INFO:Visual Rendered Successfully
2024-06-08 16:22:22,512:INFO:plot_model() successfully completed......................................
2024-06-08 16:31:16,977:INFO:Initializing plot_model()
2024-06-08 16:31:17,008:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:31:17,019:INFO:Checking exceptions
2024-06-08 16:31:17,422:INFO:Preloading libraries
2024-06-08 16:31:20,499:INFO:Copying training dataset
2024-06-08 16:31:20,500:INFO:Plot type: confusion_matrix
2024-06-08 16:31:22,629:INFO:Fitting Model
2024-06-08 16:31:22,637:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:31:22,654:INFO:Scoring test/hold-out set
2024-06-08 16:31:39,305:INFO:Visual Rendered Successfully
2024-06-08 16:31:39,584:INFO:plot_model() successfully completed......................................
2024-06-08 16:34:10,884:INFO:Initializing plot_model()
2024-06-08 16:34:10,887:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=1, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:34:10,896:INFO:Checking exceptions
2024-06-08 16:34:45,568:INFO:Initializing plot_model()
2024-06-08 16:34:45,570:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002905E1C8C10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3560, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-08 16:34:45,571:INFO:Checking exceptions
2024-06-08 16:34:45,932:INFO:Preloading libraries
2024-06-08 16:34:48,456:INFO:Copying training dataset
2024-06-08 16:34:48,490:INFO:Plot type: confusion_matrix
2024-06-08 16:34:50,213:INFO:Fitting Model
2024-06-08 16:34:50,214:WARNING:c:\Users\user\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-06-08 16:34:50,226:INFO:Scoring test/hold-out set
2024-06-08 16:35:03,987:INFO:Visual Rendered Successfully
2024-06-08 16:35:04,247:INFO:plot_model() successfully completed......................................
